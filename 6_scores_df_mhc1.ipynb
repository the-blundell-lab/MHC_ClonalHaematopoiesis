{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MHC - CH variants on all data \n",
    "- Barbara Walkowiak (bw450)\n",
    "\n",
    "- 2024-06-19, modified 2024-09-07\n",
    "\n",
    "- In this script, for each individual screened for CH in the UKB I add MHC binding scores based on their MHC genotype (class I)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib import cm\n",
    "import scipy.special\n",
    "from scipy import integrate\n",
    "import scipy.integrate as it\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import kde\n",
    "import copy\n",
    "import glob, os\n",
    "import re\n",
    "# from sklearn import datasets, linear_model\n",
    "import pandas as pd\n",
    "from decimal import *\n",
    "from operator import itemgetter    \n",
    "from collections import OrderedDict\n",
    "import timeit\n",
    "import time \n",
    "import csv\n",
    "import seaborn as sns \n",
    "import scipy as sp\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import combinations\n",
    "from scipy.stats import kruskal\n",
    "from scipy.stats import mannwhitneyu\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import statsmodels.api as sm\n",
    "import plotly.express as px\n",
    "import kaleido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify font for plotting \n",
    "plt.rcParams.update({'font.sans-serif':'Helvetica'})\n",
    "\n",
    "# stop printing warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# get current date \n",
    "timestr = time.strftime(\"%Y%m%d\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in dataframe with imputed MHC I and CH status for each participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hla1 = pd.read_csv('/Users/barbarawalkowiak/Desktop/msc_thesis/results/dataframes/20240907_df_hla1_ch_status.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions to make the HLA names uniform\n",
    "\n",
    "# transform format (from NetMHCpan data to UKBB format)\n",
    "def transform_format_netmhc(input_string):\n",
    "    \n",
    "    # a regular expression pattern to match the input format\n",
    "    pattern = re.compile(r'HLA-(\\w\\S*)(\\d{2}):(\\d{2})')\n",
    "\n",
    "    # check if there is a match\n",
    "    match = pattern.match(input_string)\n",
    "\n",
    "    # if match, apply transformation\n",
    "    if match:\n",
    "        group1 = match.group(1).replace('*', '') # remove the star \n",
    "        group2 = int(match.group(2)) # remove zeros at the start \n",
    "        group3 = match.group(3) # leave as it is \n",
    "\n",
    "        # Format the output string\n",
    "        output_string = f'{group1}_{group2}{group3}' # stitch back \n",
    "        return output_string # return transformed string \n",
    "\n",
    "    # if no much, return original string \n",
    "    return input_string\n",
    "\n",
    "# transform format (from PRIME format to UKBB format)\n",
    "def transform_format_prime(input_string):\n",
    "\n",
    "    # regular expression pattern to match the input format\n",
    "    # Nb PRIME is almost the same as NetMHC but there is no star after \"HLA-A*\"\n",
    "    pattern = re.compile(r'HLA-(\\w)(\\d{2}):(\\d{2})')\n",
    "\n",
    "    # check if there is a match\n",
    "    match = pattern.match(input_string)\n",
    "\n",
    "    # if match, apply transformation\n",
    "    if match:\n",
    "        group1 = match.group(1).replace('*', '') \n",
    "        group2 = int(match.group(2)) \n",
    "        group3 = match.group(3) \n",
    "\n",
    "        # Format the output string\n",
    "        output_string = f'{group1}_{group2}{group3}' # stitch back \n",
    "        return output_string # return transformed string \n",
    "\n",
    "    # if no match, return original string \n",
    "    return input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for everyone, assign the score for every variant examined based on their MHC I genotype \n",
    "# define the function to find best scores (possible to do this for different parameters, we chose %Rank_EL)\n",
    "\n",
    "def find_best_score_for_all_variants(row, df, param):\n",
    "\n",
    "    '''\n",
    "    row = function is applied to each row of the participant dataframe (ie run through each participant)\n",
    "\n",
    "    df = dataframe with prediction scores (like netmhc)\n",
    "\n",
    "    Allowed parameters (param) are:\n",
    "    Aff_nM - affinity (raw number)\n",
    "    Score_BA - binding affinity score\n",
    "    Score_EL - elution score\n",
    "    %Rank_BA - %Rank of binding affinity cf a set of random peptides\n",
    "    %Rank_EL - %Rank of elution cf a set of random peptides\n",
    "    '''\n",
    "\n",
    "    # get HLAs for each person \n",
    "    hlas = row.index[7:][row[7:] >= 1] # select alleles which each Person (row) carries (the first 7 columns are: Person ID, gene_var, VAF, CH status, age, depth, var_depth)\n",
    "   \n",
    "    # get variants \n",
    "    variants = df['gene_var']\n",
    "   \n",
    "    scores = {} # initialise empy dictionaries\n",
    "\n",
    "    # depending on the parameter, pick the minimum of maximum value \n",
    "    if param == \"Aff_nM\":\n",
    "        for var in variants:\n",
    "            # Find the minimum value for each variant in the category that is present\n",
    "            best_value = min(df.loc[df['gene_var'] == var, hlas].values[0])\n",
    "            # Update the dictionary with the minimum value for the corresponding variant\n",
    "            scores[f'score_{var}'] = best_value\n",
    "        return pd.Series(scores)\n",
    "\n",
    "    elif param == \"Score_BA\":\n",
    "        for var in variants:\n",
    "            \n",
    "            best_value = max(df.loc[df['gene_var'] == var, hlas].values[0])\n",
    "            scores[f'score_{var}'] = best_value\n",
    "        \n",
    "        return pd.Series(scores)\n",
    "\n",
    "    elif param == \"Score_EL\":\n",
    "        for var in variants:\n",
    "           \n",
    "            best_value = max(df.loc[df['gene_var'] == var, hlas].values[0])\n",
    "            scores[f'score_{var}'] = best_value\n",
    "\n",
    "        return pd.Series(scores)\n",
    "\n",
    "    elif param == \"%Rank_BA\":\n",
    "        for var in variants:\n",
    "\n",
    "            best_value = min(df.loc[df['gene_var'] == var, hlas].values[0])\n",
    "            scores[f'score_{var}'] = best_value\n",
    "\n",
    "        return pd.Series(scores)\n",
    "\n",
    "    # we will likely be choosing this option\n",
    "    elif param == \"%Rank_EL\":\n",
    "        for var in variants:\n",
    "            \n",
    "            best_value = min(df.loc[df['gene_var'] == var, hlas].values[0]) # choose minimum rank as the best score \n",
    "            scores[f'score_{var}'] = best_value\n",
    "\n",
    "        return pd.Series(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load binding predictions for MHC I from NetMHC I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of alleles for which predictions are available (NetMHC): 194\n",
      "Number of HLA alleles which have been identified in the UK BioBank: 215\n",
      "Number of unique variants I have predictions for (NetMHC): 54\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import NetMHC scores  \n",
    "pred_file_net = '/Users/barbarawalkowiak/Desktop/msc_thesis/netMHC_out/scores/20240716_NetMHC_HLA_UKBB_with_affinities_bestscores_allvariants.csv' # EL scores, BA scores, EL rank, BA rank, affinity prediction\n",
    "pred_filename_net = pred_file_net.split('/')[2].split('.')[0] # identify file name \n",
    "pred_method_net = pred_file_net.split('_out')[0] # identify method used to obtain predictions\n",
    "\n",
    "# load the csv\n",
    "netmhc = pd.read_csv(pred_file_net) # load the csv \n",
    "netmhc = netmhc.rename(columns={'Aff(nM)': 'Aff_nM'})\n",
    "\n",
    "# specify HLA allele naming format \n",
    "NET_col = netmhc.HLA\n",
    "NET_formatted = NET_col.apply(transform_format_netmhc)\n",
    "netmhc = pd.concat([netmhc, NET_formatted.rename('HLA_formatted')], axis = 1)\n",
    "\n",
    "# select required columns and sor values \n",
    "netmhc = netmhc[['HLA_formatted', 'Peptide', '%Rank_EL', 'Score_EL', '%Rank_BA', 'Score_BA', 'Aff_nM', 'gene', 'variant', 'genotype']]\n",
    "netmhc = netmhc.sort_values(by=['HLA_formatted', 'gene', 'variant', 'genotype'])\n",
    "\n",
    "# identify gene variants \n",
    "netmhc['gene_var_gt'] = netmhc['gene'] + '_' + netmhc['variant'] + '_' + netmhc['genotype'] # add complete genotype data\n",
    "netmhc['gene_var'] = netmhc['gene'] + '_' + netmhc['variant']\n",
    "netmhc['varID'] = netmhc['gene'] + ' ' + netmhc['variant'] # this is a column where the variant ID is in the same format as in the CH cases dataframe\n",
    "netmhc = netmhc.rename(columns={'Aff(nM)': 'Aff_nM'}) # rename affinity column \n",
    "scores_netmhc = netmhc[['HLA_formatted', 'Score_EL', '%Rank_EL', 'Score_BA', '%Rank_BA', 'Aff_nM', 'varID', 'gene_var', 'gene_var_gt']] # select columns of interest\n",
    "\n",
    "# Print the results \n",
    "print('Number of alleles for which predictions are available (NetMHC):', len(netmhc.HLA_formatted.unique()))\n",
    "\n",
    "# Find MHC alleles which have been typed in the UKBB\n",
    "hla_ukbb = df_hla1.filter(regex='\\d').columns # HLA from all UKBB\n",
    "print('Number of HLA alleles which have been identified in the UK BioBank:', len(hla_ukbb))\n",
    "\n",
    "# Now look at variants\n",
    "print('Number of unique variants I have predictions for (NetMHC):',  len(netmhc.gene_var.unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variants identified in CH screening vs variants we have predictions for (all variants screened for should be covered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variants identified in the UKBB from CH screening: 40\n",
      "Number or variants I have predictions for (NetMHC): 54\n",
      "List of variants examined: ['DNMT3A_P904L', 'DNMT3A_P904Q', 'DNMT3A_P904R', 'DNMT3A_R320*', 'DNMT3A_R326C', 'DNMT3A_R326G', 'DNMT3A_R326S', 'DNMT3A_R598*', 'DNMT3A_R729G', 'DNMT3A_R729W', 'DNMT3A_R736C', 'DNMT3A_R736G', 'DNMT3A_R736H', 'DNMT3A_R736L', 'DNMT3A_R736S', 'DNMT3A_R771*', 'DNMT3A_R882C', 'DNMT3A_R882H', 'DNMT3A_R882L', 'DNMT3A_R882P', 'DNMT3A_R882S', 'DNMT3A_Y735C', 'DNMT3A_Y735F', 'DNMT3A_Y735S', 'GNB1_K57E', 'IDH1_R132H', 'IDH2_R140Q', 'IDH2_R172K', 'JAK2_V617F', 'KRAS_G12D', 'KRAS_G12S', 'MPL_W515L', 'NRAS_G12D', 'SF3B1_K666N', 'SF3B1_K700E', 'SRSF2_P95H', 'SRSF2_P95L', 'SRSF2_P95R', 'TP53_R175H', 'TP53_R273H']\n",
      "List of variants with NetMHC predictions: ['DNMT3A_P904L', 'DNMT3A_P904Q', 'DNMT3A_P904R', 'DNMT3A_R320*', 'DNMT3A_R326C', 'DNMT3A_R326G', 'DNMT3A_R326S', 'DNMT3A_R598*', 'DNMT3A_R598G', 'DNMT3A_R729G', 'DNMT3A_R729W', 'DNMT3A_R736C', 'DNMT3A_R736G', 'DNMT3A_R736H', 'DNMT3A_R736L', 'DNMT3A_R736P', 'DNMT3A_R736S', 'DNMT3A_R771*', 'DNMT3A_R771G', 'DNMT3A_R882C', 'DNMT3A_R882G', 'DNMT3A_R882H', 'DNMT3A_R882L', 'DNMT3A_R882P', 'DNMT3A_R882S', 'DNMT3A_Y735C', 'DNMT3A_Y735F', 'DNMT3A_Y735S', 'GNB1_K57E', 'IDH1_R132H', 'IDH2_R140L', 'IDH2_R140Q', 'IDH2_R172K', 'JAK2_V617F', 'KIT_D816G', 'KIT_D816V', 'KRAS_G12A', 'KRAS_G12D', 'KRAS_G12S', 'KRAS_G12V', 'MPL_W515*', 'MPL_W515L', 'NRAS_G12A', 'NRAS_G12C', 'NRAS_G12D', 'NRAS_G12S', 'NRAS_G12V', 'SF3B1_K666N', 'SF3B1_K700E', 'SRSF2_P95H', 'SRSF2_P95L', 'SRSF2_P95R', 'TP53_R175H', 'TP53_R273H']\n"
     ]
    }
   ],
   "source": [
    "print('Number of variants identified in the UKBB from CH screening:', len(df_hla1.gene_var.unique())-1) # NB this list also includes 'NaN'\n",
    "print('Number or variants I have predictions for (NetMHC):',  len(netmhc.gene_var.unique()))\n",
    "\n",
    "variants_in_ukbb = df_hla1.gene_var.unique().tolist()\n",
    "variants_in_ukbb = [x for x in variants_in_ukbb if str(x) != 'nan']\n",
    "print('List of variants examined:', sorted(variants_in_ukbb))\n",
    "print('List of variants with NetMHC predictions:',  sorted(netmhc.gene_var.unique())) # also includes predictions for variants which turned out not to be common enough  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_var_gt</th>\n",
       "      <th>A_101</th>\n",
       "      <th>A_102</th>\n",
       "      <th>A_103</th>\n",
       "      <th>A_1101</th>\n",
       "      <th>A_1102</th>\n",
       "      <th>A_1103</th>\n",
       "      <th>A_201</th>\n",
       "      <th>A_202</th>\n",
       "      <th>A_203</th>\n",
       "      <th>...</th>\n",
       "      <th>C_403</th>\n",
       "      <th>C_407</th>\n",
       "      <th>C_501</th>\n",
       "      <th>C_602</th>\n",
       "      <th>C_701</th>\n",
       "      <th>C_702</th>\n",
       "      <th>C_704</th>\n",
       "      <th>C_801</th>\n",
       "      <th>C_802</th>\n",
       "      <th>C_804</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNMT3A_P904L_ch</td>\n",
       "      <td>1.304</td>\n",
       "      <td>1.295</td>\n",
       "      <td>1.163</td>\n",
       "      <td>2.286</td>\n",
       "      <td>2.286</td>\n",
       "      <td>1.618</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.238</td>\n",
       "      <td>...</td>\n",
       "      <td>3.376</td>\n",
       "      <td>1.829</td>\n",
       "      <td>4.538</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.951</td>\n",
       "      <td>1.073</td>\n",
       "      <td>2.260</td>\n",
       "      <td>2.349</td>\n",
       "      <td>4.492</td>\n",
       "      <td>2.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DNMT3A_P904L_refseq</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.844</td>\n",
       "      <td>1.602</td>\n",
       "      <td>1.602</td>\n",
       "      <td>0.793</td>\n",
       "      <td>2.147</td>\n",
       "      <td>2.519</td>\n",
       "      <td>1.271</td>\n",
       "      <td>...</td>\n",
       "      <td>1.485</td>\n",
       "      <td>0.405</td>\n",
       "      <td>2.360</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.857</td>\n",
       "      <td>1.867</td>\n",
       "      <td>2.322</td>\n",
       "      <td>2.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DNMT3A_P904Q_ch</td>\n",
       "      <td>1.018</td>\n",
       "      <td>1.049</td>\n",
       "      <td>0.902</td>\n",
       "      <td>2.498</td>\n",
       "      <td>2.498</td>\n",
       "      <td>1.530</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.235</td>\n",
       "      <td>...</td>\n",
       "      <td>2.449</td>\n",
       "      <td>1.157</td>\n",
       "      <td>2.847</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.768</td>\n",
       "      <td>2.334</td>\n",
       "      <td>2.087</td>\n",
       "      <td>2.773</td>\n",
       "      <td>2.327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DNMT3A_P904Q_refseq</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.844</td>\n",
       "      <td>1.602</td>\n",
       "      <td>1.602</td>\n",
       "      <td>0.793</td>\n",
       "      <td>2.147</td>\n",
       "      <td>2.519</td>\n",
       "      <td>1.271</td>\n",
       "      <td>...</td>\n",
       "      <td>1.485</td>\n",
       "      <td>0.405</td>\n",
       "      <td>2.360</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.857</td>\n",
       "      <td>1.867</td>\n",
       "      <td>2.322</td>\n",
       "      <td>2.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DNMT3A_P904R_ch</td>\n",
       "      <td>1.331</td>\n",
       "      <td>1.437</td>\n",
       "      <td>1.222</td>\n",
       "      <td>2.440</td>\n",
       "      <td>2.440</td>\n",
       "      <td>1.650</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.091</td>\n",
       "      <td>...</td>\n",
       "      <td>6.394</td>\n",
       "      <td>2.204</td>\n",
       "      <td>6.166</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.491</td>\n",
       "      <td>1.427</td>\n",
       "      <td>6.255</td>\n",
       "      <td>8.836</td>\n",
       "      <td>5.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>SRSF2_P95R_refseq</td>\n",
       "      <td>6.221</td>\n",
       "      <td>3.614</td>\n",
       "      <td>6.530</td>\n",
       "      <td>4.539</td>\n",
       "      <td>4.539</td>\n",
       "      <td>5.012</td>\n",
       "      <td>21.355</td>\n",
       "      <td>15.723</td>\n",
       "      <td>12.063</td>\n",
       "      <td>...</td>\n",
       "      <td>5.934</td>\n",
       "      <td>3.531</td>\n",
       "      <td>7.691</td>\n",
       "      <td>4.075</td>\n",
       "      <td>1.232</td>\n",
       "      <td>2.088</td>\n",
       "      <td>6.109</td>\n",
       "      <td>11.847</td>\n",
       "      <td>6.015</td>\n",
       "      <td>10.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>TP53_R175H_ch</td>\n",
       "      <td>5.285</td>\n",
       "      <td>5.159</td>\n",
       "      <td>6.238</td>\n",
       "      <td>3.879</td>\n",
       "      <td>3.879</td>\n",
       "      <td>3.415</td>\n",
       "      <td>1.761</td>\n",
       "      <td>1.447</td>\n",
       "      <td>1.270</td>\n",
       "      <td>...</td>\n",
       "      <td>11.861</td>\n",
       "      <td>9.305</td>\n",
       "      <td>13.711</td>\n",
       "      <td>3.284</td>\n",
       "      <td>2.270</td>\n",
       "      <td>3.036</td>\n",
       "      <td>2.763</td>\n",
       "      <td>9.837</td>\n",
       "      <td>13.844</td>\n",
       "      <td>7.516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>TP53_R175H_refseq</td>\n",
       "      <td>9.617</td>\n",
       "      <td>6.019</td>\n",
       "      <td>11.430</td>\n",
       "      <td>2.145</td>\n",
       "      <td>2.145</td>\n",
       "      <td>2.412</td>\n",
       "      <td>2.504</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.706</td>\n",
       "      <td>...</td>\n",
       "      <td>13.622</td>\n",
       "      <td>10.869</td>\n",
       "      <td>14.295</td>\n",
       "      <td>2.364</td>\n",
       "      <td>1.979</td>\n",
       "      <td>4.188</td>\n",
       "      <td>3.226</td>\n",
       "      <td>12.513</td>\n",
       "      <td>16.362</td>\n",
       "      <td>9.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>TP53_R273H_ch</td>\n",
       "      <td>7.237</td>\n",
       "      <td>10.392</td>\n",
       "      <td>7.881</td>\n",
       "      <td>7.668</td>\n",
       "      <td>7.668</td>\n",
       "      <td>8.440</td>\n",
       "      <td>1.913</td>\n",
       "      <td>2.140</td>\n",
       "      <td>3.311</td>\n",
       "      <td>...</td>\n",
       "      <td>10.534</td>\n",
       "      <td>4.467</td>\n",
       "      <td>8.629</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.266</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.579</td>\n",
       "      <td>3.201</td>\n",
       "      <td>9.857</td>\n",
       "      <td>3.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>TP53_R273H_refseq</td>\n",
       "      <td>12.027</td>\n",
       "      <td>15.387</td>\n",
       "      <td>12.097</td>\n",
       "      <td>4.330</td>\n",
       "      <td>4.330</td>\n",
       "      <td>3.495</td>\n",
       "      <td>2.593</td>\n",
       "      <td>2.825</td>\n",
       "      <td>4.063</td>\n",
       "      <td>...</td>\n",
       "      <td>15.407</td>\n",
       "      <td>5.995</td>\n",
       "      <td>13.266</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.382</td>\n",
       "      <td>1.790</td>\n",
       "      <td>1.014</td>\n",
       "      <td>5.118</td>\n",
       "      <td>13.606</td>\n",
       "      <td>5.822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             gene_var_gt   A_101   A_102   A_103  A_1101  A_1102  A_1103  \\\n",
       "0        DNMT3A_P904L_ch   1.304   1.295   1.163   2.286   2.286   1.618   \n",
       "1    DNMT3A_P904L_refseq   0.968   0.884   0.844   1.602   1.602   0.793   \n",
       "2        DNMT3A_P904Q_ch   1.018   1.049   0.902   2.498   2.498   1.530   \n",
       "3    DNMT3A_P904Q_refseq   0.968   0.884   0.844   1.602   1.602   0.793   \n",
       "4        DNMT3A_P904R_ch   1.331   1.437   1.222   2.440   2.440   1.650   \n",
       "..                   ...     ...     ...     ...     ...     ...     ...   \n",
       "103    SRSF2_P95R_refseq   6.221   3.614   6.530   4.539   4.539   5.012   \n",
       "104        TP53_R175H_ch   5.285   5.159   6.238   3.879   3.879   3.415   \n",
       "105    TP53_R175H_refseq   9.617   6.019  11.430   2.145   2.145   2.412   \n",
       "106        TP53_R273H_ch   7.237  10.392   7.881   7.668   7.668   8.440   \n",
       "107    TP53_R273H_refseq  12.027  15.387  12.097   4.330   4.330   3.495   \n",
       "\n",
       "      A_201   A_202   A_203  ...   C_403   C_407   C_501  C_602  C_701  C_702  \\\n",
       "0     0.753   0.645   0.238  ...   3.376   1.829   4.538  0.771  0.951  1.073   \n",
       "1     2.147   2.519   1.271  ...   1.485   0.405   2.360  0.822  0.643  0.273   \n",
       "2     0.807   0.565   0.235  ...   2.449   1.157   2.847  0.655  0.804  0.768   \n",
       "3     2.147   2.519   1.271  ...   1.485   0.405   2.360  0.822  0.643  0.273   \n",
       "4     0.361   0.321   0.091  ...   6.394   2.204   6.166  0.513  0.504  0.491   \n",
       "..      ...     ...     ...  ...     ...     ...     ...    ...    ...    ...   \n",
       "103  21.355  15.723  12.063  ...   5.934   3.531   7.691  4.075  1.232  2.088   \n",
       "104   1.761   1.447   1.270  ...  11.861   9.305  13.711  3.284  2.270  3.036   \n",
       "105   2.504   2.000   1.706  ...  13.622  10.869  14.295  2.364  1.979  4.188   \n",
       "106   1.913   2.140   3.311  ...  10.534   4.467   8.629  0.132  0.266  1.034   \n",
       "107   2.593   2.825   4.063  ...  15.407   5.995  13.266  0.173  0.382  1.790   \n",
       "\n",
       "     C_704   C_801   C_802   C_804  \n",
       "0    2.260   2.349   4.492   2.495  \n",
       "1    0.857   1.867   2.322   2.149  \n",
       "2    2.334   2.087   2.773   2.327  \n",
       "3    0.857   1.867   2.322   2.149  \n",
       "4    1.427   6.255   8.836   5.360  \n",
       "..     ...     ...     ...     ...  \n",
       "103  6.109  11.847   6.015  10.009  \n",
       "104  2.763   9.837  13.844   7.516  \n",
       "105  3.226  12.513  16.362   9.801  \n",
       "106  0.579   3.201   9.857   3.914  \n",
       "107  1.014   5.118  13.606   5.822  \n",
       "\n",
       "[108 rows x 195 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# create a suitably formatted NetMHC df \n",
    "param = '%Rank_EL'\n",
    "netmhc_sub = netmhc[['HLA_formatted', 'gene_var_gt', param]]\n",
    "netmhc_sub_wide = pd.pivot(netmhc_sub, index='gene_var_gt', columns='HLA_formatted', values=param)\n",
    "netmhc_sub_wide = netmhc_sub_wide.reset_index() # this is to make sure that you have the gene_var column in there too \n",
    "netmhc_sub_wide.columns = map(transform_format_netmhc, netmhc_sub_wide.columns)\n",
    "netmhc_sub_wide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a list of HLA alleles genotyped in the UKBB for which predictions are available\n",
    "hla_intersect = netmhc_sub_wide.columns[netmhc_sub_wide.columns.isin(hla_ukbb)] # HLA in the UKBB which I have predictions for \n",
    "hla_intersect_list = hla_intersect.tolist() # 194 alleles \n",
    "\n",
    "# create the prediction dataset \n",
    "netmhc_sub = netmhc_sub_wide[hla_intersect_list + netmhc_sub_wide.columns[netmhc_sub_wide.columns.str.contains('gene_var')].tolist()] # subset netmhc so you only have alleles which are in the UKBB, also 194\n",
    "netmhc_sub = netmhc_sub[netmhc_sub['gene_var_gt'].str.contains('_ch', regex=True)] # retain CH scores only \n",
    "netmhc_sub['gene_var'] = netmhc_sub['gene_var_gt'].str.replace('_ch', '') # remove the ch / refseq annotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_101</th>\n",
       "      <th>A_102</th>\n",
       "      <th>A_103</th>\n",
       "      <th>A_1101</th>\n",
       "      <th>A_1102</th>\n",
       "      <th>A_1103</th>\n",
       "      <th>A_201</th>\n",
       "      <th>A_202</th>\n",
       "      <th>A_203</th>\n",
       "      <th>A_205</th>\n",
       "      <th>...</th>\n",
       "      <th>C_501</th>\n",
       "      <th>C_602</th>\n",
       "      <th>C_701</th>\n",
       "      <th>C_702</th>\n",
       "      <th>C_704</th>\n",
       "      <th>C_801</th>\n",
       "      <th>C_802</th>\n",
       "      <th>C_804</th>\n",
       "      <th>gene_var_gt</th>\n",
       "      <th>gene_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.304</td>\n",
       "      <td>1.295</td>\n",
       "      <td>1.163</td>\n",
       "      <td>2.286</td>\n",
       "      <td>2.286</td>\n",
       "      <td>1.618</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.974</td>\n",
       "      <td>...</td>\n",
       "      <td>4.538</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.951</td>\n",
       "      <td>1.073</td>\n",
       "      <td>2.260</td>\n",
       "      <td>2.349</td>\n",
       "      <td>4.492</td>\n",
       "      <td>2.495</td>\n",
       "      <td>DNMT3A_P904L_ch</td>\n",
       "      <td>DNMT3A_P904L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.018</td>\n",
       "      <td>1.049</td>\n",
       "      <td>0.902</td>\n",
       "      <td>2.498</td>\n",
       "      <td>2.498</td>\n",
       "      <td>1.530</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.752</td>\n",
       "      <td>...</td>\n",
       "      <td>2.847</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.768</td>\n",
       "      <td>2.334</td>\n",
       "      <td>2.087</td>\n",
       "      <td>2.773</td>\n",
       "      <td>2.327</td>\n",
       "      <td>DNMT3A_P904Q_ch</td>\n",
       "      <td>DNMT3A_P904Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.331</td>\n",
       "      <td>1.437</td>\n",
       "      <td>1.222</td>\n",
       "      <td>2.440</td>\n",
       "      <td>2.440</td>\n",
       "      <td>1.650</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.439</td>\n",
       "      <td>...</td>\n",
       "      <td>6.166</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.491</td>\n",
       "      <td>1.427</td>\n",
       "      <td>6.255</td>\n",
       "      <td>8.836</td>\n",
       "      <td>5.360</td>\n",
       "      <td>DNMT3A_P904R_ch</td>\n",
       "      <td>DNMT3A_P904R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37.267</td>\n",
       "      <td>47.917</td>\n",
       "      <td>36.111</td>\n",
       "      <td>27.250</td>\n",
       "      <td>27.250</td>\n",
       "      <td>23.808</td>\n",
       "      <td>52.667</td>\n",
       "      <td>55.000</td>\n",
       "      <td>47.400</td>\n",
       "      <td>60.417</td>\n",
       "      <td>...</td>\n",
       "      <td>52.000</td>\n",
       "      <td>61.667</td>\n",
       "      <td>53.333</td>\n",
       "      <td>50.000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>45.000</td>\n",
       "      <td>52.500</td>\n",
       "      <td>38.333</td>\n",
       "      <td>DNMT3A_R320*_ch</td>\n",
       "      <td>DNMT3A_R320*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.837</td>\n",
       "      <td>4.932</td>\n",
       "      <td>4.312</td>\n",
       "      <td>2.104</td>\n",
       "      <td>2.104</td>\n",
       "      <td>2.983</td>\n",
       "      <td>3.226</td>\n",
       "      <td>2.774</td>\n",
       "      <td>3.044</td>\n",
       "      <td>1.188</td>\n",
       "      <td>...</td>\n",
       "      <td>1.078</td>\n",
       "      <td>1.749</td>\n",
       "      <td>0.881</td>\n",
       "      <td>1.618</td>\n",
       "      <td>3.397</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.738</td>\n",
       "      <td>1.085</td>\n",
       "      <td>DNMT3A_R326C_ch</td>\n",
       "      <td>DNMT3A_R326C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.122</td>\n",
       "      <td>2.566</td>\n",
       "      <td>1.955</td>\n",
       "      <td>1.539</td>\n",
       "      <td>1.539</td>\n",
       "      <td>1.707</td>\n",
       "      <td>6.313</td>\n",
       "      <td>4.497</td>\n",
       "      <td>3.213</td>\n",
       "      <td>1.820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356</td>\n",
       "      <td>1.624</td>\n",
       "      <td>0.992</td>\n",
       "      <td>1.683</td>\n",
       "      <td>3.454</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.222</td>\n",
       "      <td>DNMT3A_R326G_ch</td>\n",
       "      <td>DNMT3A_R326G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.071</td>\n",
       "      <td>2.607</td>\n",
       "      <td>1.932</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.972</td>\n",
       "      <td>2.538</td>\n",
       "      <td>1.634</td>\n",
       "      <td>1.243</td>\n",
       "      <td>0.539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.699</td>\n",
       "      <td>1.781</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.233</td>\n",
       "      <td>DNMT3A_R326S_ch</td>\n",
       "      <td>DNMT3A_R326S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>23.380</td>\n",
       "      <td>22.913</td>\n",
       "      <td>25.087</td>\n",
       "      <td>1.678</td>\n",
       "      <td>1.678</td>\n",
       "      <td>1.514</td>\n",
       "      <td>30.909</td>\n",
       "      <td>45.538</td>\n",
       "      <td>32.714</td>\n",
       "      <td>36.703</td>\n",
       "      <td>...</td>\n",
       "      <td>56.250</td>\n",
       "      <td>32.750</td>\n",
       "      <td>21.231</td>\n",
       "      <td>22.812</td>\n",
       "      <td>55.000</td>\n",
       "      <td>49.000</td>\n",
       "      <td>65.000</td>\n",
       "      <td>51.250</td>\n",
       "      <td>DNMT3A_R598*_ch</td>\n",
       "      <td>DNMT3A_R598*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.811</td>\n",
       "      <td>1.196</td>\n",
       "      <td>0.766</td>\n",
       "      <td>2.261</td>\n",
       "      <td>2.261</td>\n",
       "      <td>3.622</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.242</td>\n",
       "      <td>...</td>\n",
       "      <td>3.118</td>\n",
       "      <td>4.558</td>\n",
       "      <td>1.804</td>\n",
       "      <td>0.599</td>\n",
       "      <td>1.615</td>\n",
       "      <td>3.944</td>\n",
       "      <td>2.924</td>\n",
       "      <td>3.740</td>\n",
       "      <td>DNMT3A_R729G_ch</td>\n",
       "      <td>DNMT3A_R729G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.603</td>\n",
       "      <td>1.265</td>\n",
       "      <td>1.485</td>\n",
       "      <td>2.978</td>\n",
       "      <td>2.978</td>\n",
       "      <td>5.565</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.397</td>\n",
       "      <td>...</td>\n",
       "      <td>2.903</td>\n",
       "      <td>4.263</td>\n",
       "      <td>1.218</td>\n",
       "      <td>0.336</td>\n",
       "      <td>1.324</td>\n",
       "      <td>4.146</td>\n",
       "      <td>2.917</td>\n",
       "      <td>4.521</td>\n",
       "      <td>DNMT3A_R729W_ch</td>\n",
       "      <td>DNMT3A_R729W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.050</td>\n",
       "      <td>2.747</td>\n",
       "      <td>9.735</td>\n",
       "      <td>2.858</td>\n",
       "      <td>2.858</td>\n",
       "      <td>2.341</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.981</td>\n",
       "      <td>2.132</td>\n",
       "      <td>1.750</td>\n",
       "      <td>...</td>\n",
       "      <td>8.079</td>\n",
       "      <td>3.191</td>\n",
       "      <td>6.357</td>\n",
       "      <td>2.433</td>\n",
       "      <td>4.691</td>\n",
       "      <td>7.322</td>\n",
       "      <td>9.543</td>\n",
       "      <td>6.963</td>\n",
       "      <td>DNMT3A_R736C_ch</td>\n",
       "      <td>DNMT3A_R736C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.369</td>\n",
       "      <td>0.999</td>\n",
       "      <td>4.242</td>\n",
       "      <td>1.774</td>\n",
       "      <td>1.774</td>\n",
       "      <td>1.085</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.772</td>\n",
       "      <td>...</td>\n",
       "      <td>6.946</td>\n",
       "      <td>3.513</td>\n",
       "      <td>5.358</td>\n",
       "      <td>2.802</td>\n",
       "      <td>4.899</td>\n",
       "      <td>7.415</td>\n",
       "      <td>5.025</td>\n",
       "      <td>7.816</td>\n",
       "      <td>DNMT3A_R736G_ch</td>\n",
       "      <td>DNMT3A_R736G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.132</td>\n",
       "      <td>0.867</td>\n",
       "      <td>3.889</td>\n",
       "      <td>1.766</td>\n",
       "      <td>1.766</td>\n",
       "      <td>1.168</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.251</td>\n",
       "      <td>...</td>\n",
       "      <td>2.785</td>\n",
       "      <td>0.520</td>\n",
       "      <td>1.099</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.511</td>\n",
       "      <td>2.997</td>\n",
       "      <td>2.356</td>\n",
       "      <td>3.039</td>\n",
       "      <td>DNMT3A_R736H_ch</td>\n",
       "      <td>DNMT3A_R736H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.969</td>\n",
       "      <td>1.624</td>\n",
       "      <td>6.492</td>\n",
       "      <td>2.457</td>\n",
       "      <td>2.457</td>\n",
       "      <td>1.671</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.377</td>\n",
       "      <td>1.164</td>\n",
       "      <td>0.822</td>\n",
       "      <td>...</td>\n",
       "      <td>5.386</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.815</td>\n",
       "      <td>1.583</td>\n",
       "      <td>5.327</td>\n",
       "      <td>5.324</td>\n",
       "      <td>5.934</td>\n",
       "      <td>DNMT3A_R736L_ch</td>\n",
       "      <td>DNMT3A_R736L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.976</td>\n",
       "      <td>0.878</td>\n",
       "      <td>3.657</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.405</td>\n",
       "      <td>...</td>\n",
       "      <td>4.386</td>\n",
       "      <td>1.297</td>\n",
       "      <td>2.964</td>\n",
       "      <td>0.873</td>\n",
       "      <td>1.432</td>\n",
       "      <td>2.843</td>\n",
       "      <td>3.173</td>\n",
       "      <td>2.927</td>\n",
       "      <td>DNMT3A_R736S_ch</td>\n",
       "      <td>DNMT3A_R736S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10.538</td>\n",
       "      <td>17.129</td>\n",
       "      <td>11.839</td>\n",
       "      <td>35.667</td>\n",
       "      <td>35.667</td>\n",
       "      <td>35.333</td>\n",
       "      <td>44.200</td>\n",
       "      <td>37.690</td>\n",
       "      <td>35.938</td>\n",
       "      <td>32.750</td>\n",
       "      <td>...</td>\n",
       "      <td>7.169</td>\n",
       "      <td>50.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>37.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>6.772</td>\n",
       "      <td>20.486</td>\n",
       "      <td>DNMT3A_R771*_ch</td>\n",
       "      <td>DNMT3A_R771*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.787</td>\n",
       "      <td>2.191</td>\n",
       "      <td>0.697</td>\n",
       "      <td>2.177</td>\n",
       "      <td>2.177</td>\n",
       "      <td>2.709</td>\n",
       "      <td>5.803</td>\n",
       "      <td>6.852</td>\n",
       "      <td>10.156</td>\n",
       "      <td>4.253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185</td>\n",
       "      <td>4.754</td>\n",
       "      <td>5.046</td>\n",
       "      <td>2.706</td>\n",
       "      <td>2.400</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.326</td>\n",
       "      <td>DNMT3A_R882C_ch</td>\n",
       "      <td>DNMT3A_R882C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.107</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.117</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.322</td>\n",
       "      <td>4.719</td>\n",
       "      <td>4.029</td>\n",
       "      <td>6.011</td>\n",
       "      <td>1.694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.280</td>\n",
       "      <td>DNMT3A_R882H_ch</td>\n",
       "      <td>DNMT3A_R882H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.173</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.787</td>\n",
       "      <td>1.044</td>\n",
       "      <td>1.035</td>\n",
       "      <td>0.460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.154</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>DNMT3A_R882L_ch</td>\n",
       "      <td>DNMT3A_R882L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.834</td>\n",
       "      <td>2.394</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.813</td>\n",
       "      <td>5.985</td>\n",
       "      <td>2.289</td>\n",
       "      <td>4.712</td>\n",
       "      <td>2.949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183</td>\n",
       "      <td>1.849</td>\n",
       "      <td>2.528</td>\n",
       "      <td>2.834</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.322</td>\n",
       "      <td>DNMT3A_R882P_ch</td>\n",
       "      <td>DNMT3A_R882P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.624</td>\n",
       "      <td>1.880</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.797</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.701</td>\n",
       "      <td>3.997</td>\n",
       "      <td>4.955</td>\n",
       "      <td>1.719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.519</td>\n",
       "      <td>1.257</td>\n",
       "      <td>1.488</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.185</td>\n",
       "      <td>DNMT3A_R882S_ch</td>\n",
       "      <td>DNMT3A_R882S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.860</td>\n",
       "      <td>1.959</td>\n",
       "      <td>11.349</td>\n",
       "      <td>6.057</td>\n",
       "      <td>6.057</td>\n",
       "      <td>4.909</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.878</td>\n",
       "      <td>1.070</td>\n",
       "      <td>1.795</td>\n",
       "      <td>...</td>\n",
       "      <td>8.034</td>\n",
       "      <td>0.895</td>\n",
       "      <td>2.675</td>\n",
       "      <td>1.053</td>\n",
       "      <td>3.474</td>\n",
       "      <td>7.095</td>\n",
       "      <td>6.775</td>\n",
       "      <td>8.528</td>\n",
       "      <td>DNMT3A_Y735C_ch</td>\n",
       "      <td>DNMT3A_Y735C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.096</td>\n",
       "      <td>1.397</td>\n",
       "      <td>7.371</td>\n",
       "      <td>3.530</td>\n",
       "      <td>3.530</td>\n",
       "      <td>3.877</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.527</td>\n",
       "      <td>...</td>\n",
       "      <td>3.982</td>\n",
       "      <td>0.296</td>\n",
       "      <td>1.012</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.935</td>\n",
       "      <td>4.070</td>\n",
       "      <td>4.173</td>\n",
       "      <td>5.084</td>\n",
       "      <td>DNMT3A_Y735F_ch</td>\n",
       "      <td>DNMT3A_Y735F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>3.606</td>\n",
       "      <td>0.898</td>\n",
       "      <td>4.211</td>\n",
       "      <td>3.122</td>\n",
       "      <td>3.122</td>\n",
       "      <td>2.145</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.596</td>\n",
       "      <td>...</td>\n",
       "      <td>3.090</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.493</td>\n",
       "      <td>2.423</td>\n",
       "      <td>2.179</td>\n",
       "      <td>2.724</td>\n",
       "      <td>DNMT3A_Y735S_ch</td>\n",
       "      <td>DNMT3A_Y735S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1.312</td>\n",
       "      <td>1.139</td>\n",
       "      <td>1.314</td>\n",
       "      <td>2.534</td>\n",
       "      <td>2.534</td>\n",
       "      <td>2.208</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.776</td>\n",
       "      <td>...</td>\n",
       "      <td>5.807</td>\n",
       "      <td>1.761</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.613</td>\n",
       "      <td>1.496</td>\n",
       "      <td>3.652</td>\n",
       "      <td>5.966</td>\n",
       "      <td>4.333</td>\n",
       "      <td>GNB1_K57E_ch</td>\n",
       "      <td>GNB1_K57E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1.997</td>\n",
       "      <td>1.832</td>\n",
       "      <td>1.933</td>\n",
       "      <td>4.071</td>\n",
       "      <td>4.071</td>\n",
       "      <td>2.577</td>\n",
       "      <td>16.810</td>\n",
       "      <td>13.763</td>\n",
       "      <td>9.018</td>\n",
       "      <td>6.278</td>\n",
       "      <td>...</td>\n",
       "      <td>15.898</td>\n",
       "      <td>7.249</td>\n",
       "      <td>1.921</td>\n",
       "      <td>1.082</td>\n",
       "      <td>8.741</td>\n",
       "      <td>6.631</td>\n",
       "      <td>10.763</td>\n",
       "      <td>8.806</td>\n",
       "      <td>IDH1_R132H_ch</td>\n",
       "      <td>IDH1_R132H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>8.969</td>\n",
       "      <td>6.388</td>\n",
       "      <td>7.928</td>\n",
       "      <td>1.531</td>\n",
       "      <td>1.531</td>\n",
       "      <td>1.839</td>\n",
       "      <td>5.546</td>\n",
       "      <td>6.663</td>\n",
       "      <td>4.196</td>\n",
       "      <td>3.568</td>\n",
       "      <td>...</td>\n",
       "      <td>3.170</td>\n",
       "      <td>2.660</td>\n",
       "      <td>2.341</td>\n",
       "      <td>3.262</td>\n",
       "      <td>1.067</td>\n",
       "      <td>1.855</td>\n",
       "      <td>2.299</td>\n",
       "      <td>2.352</td>\n",
       "      <td>IDH2_R140Q_ch</td>\n",
       "      <td>IDH2_R140Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1.408</td>\n",
       "      <td>1.838</td>\n",
       "      <td>1.311</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.093</td>\n",
       "      <td>25.268</td>\n",
       "      <td>18.919</td>\n",
       "      <td>15.070</td>\n",
       "      <td>12.667</td>\n",
       "      <td>...</td>\n",
       "      <td>18.549</td>\n",
       "      <td>4.905</td>\n",
       "      <td>2.849</td>\n",
       "      <td>2.368</td>\n",
       "      <td>9.583</td>\n",
       "      <td>9.250</td>\n",
       "      <td>11.820</td>\n",
       "      <td>7.419</td>\n",
       "      <td>IDH2_R172K_ch</td>\n",
       "      <td>IDH2_R172K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>10.487</td>\n",
       "      <td>11.425</td>\n",
       "      <td>8.966</td>\n",
       "      <td>13.886</td>\n",
       "      <td>13.886</td>\n",
       "      <td>11.469</td>\n",
       "      <td>3.408</td>\n",
       "      <td>3.793</td>\n",
       "      <td>5.692</td>\n",
       "      <td>4.234</td>\n",
       "      <td>...</td>\n",
       "      <td>2.036</td>\n",
       "      <td>14.322</td>\n",
       "      <td>13.655</td>\n",
       "      <td>11.722</td>\n",
       "      <td>7.748</td>\n",
       "      <td>3.396</td>\n",
       "      <td>4.070</td>\n",
       "      <td>5.014</td>\n",
       "      <td>JAK2_V617F_ch</td>\n",
       "      <td>JAK2_V617F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>7.425</td>\n",
       "      <td>11.104</td>\n",
       "      <td>7.595</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.552</td>\n",
       "      <td>5.155</td>\n",
       "      <td>4.956</td>\n",
       "      <td>3.298</td>\n",
       "      <td>2.880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409</td>\n",
       "      <td>21.000</td>\n",
       "      <td>16.969</td>\n",
       "      <td>12.926</td>\n",
       "      <td>6.380</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.438</td>\n",
       "      <td>KRAS_G12D_ch</td>\n",
       "      <td>KRAS_G12D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>15.302</td>\n",
       "      <td>13.938</td>\n",
       "      <td>14.158</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.166</td>\n",
       "      <td>4.321</td>\n",
       "      <td>4.333</td>\n",
       "      <td>1.923</td>\n",
       "      <td>2.260</td>\n",
       "      <td>...</td>\n",
       "      <td>3.642</td>\n",
       "      <td>10.106</td>\n",
       "      <td>13.345</td>\n",
       "      <td>17.314</td>\n",
       "      <td>6.201</td>\n",
       "      <td>2.320</td>\n",
       "      <td>2.200</td>\n",
       "      <td>1.779</td>\n",
       "      <td>KRAS_G12S_ch</td>\n",
       "      <td>KRAS_G12S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2.389</td>\n",
       "      <td>2.160</td>\n",
       "      <td>2.318</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.938</td>\n",
       "      <td>1.306</td>\n",
       "      <td>2.384</td>\n",
       "      <td>2.653</td>\n",
       "      <td>...</td>\n",
       "      <td>8.233</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.074</td>\n",
       "      <td>3.671</td>\n",
       "      <td>9.010</td>\n",
       "      <td>10.122</td>\n",
       "      <td>8.892</td>\n",
       "      <td>MPL_W515L_ch</td>\n",
       "      <td>MPL_W515L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>7.425</td>\n",
       "      <td>11.104</td>\n",
       "      <td>7.595</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.552</td>\n",
       "      <td>5.155</td>\n",
       "      <td>4.956</td>\n",
       "      <td>3.298</td>\n",
       "      <td>2.880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409</td>\n",
       "      <td>21.000</td>\n",
       "      <td>16.969</td>\n",
       "      <td>12.926</td>\n",
       "      <td>6.380</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.438</td>\n",
       "      <td>NRAS_G12D_ch</td>\n",
       "      <td>NRAS_G12D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>12.741</td>\n",
       "      <td>9.624</td>\n",
       "      <td>13.538</td>\n",
       "      <td>7.852</td>\n",
       "      <td>7.852</td>\n",
       "      <td>8.903</td>\n",
       "      <td>4.174</td>\n",
       "      <td>3.470</td>\n",
       "      <td>4.222</td>\n",
       "      <td>2.355</td>\n",
       "      <td>...</td>\n",
       "      <td>4.795</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.344</td>\n",
       "      <td>1.068</td>\n",
       "      <td>0.587</td>\n",
       "      <td>2.042</td>\n",
       "      <td>6.131</td>\n",
       "      <td>2.336</td>\n",
       "      <td>SF3B1_K666N_ch</td>\n",
       "      <td>SF3B1_K666N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2.377</td>\n",
       "      <td>2.483</td>\n",
       "      <td>1.906</td>\n",
       "      <td>3.220</td>\n",
       "      <td>3.220</td>\n",
       "      <td>5.287</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169</td>\n",
       "      <td>5.033</td>\n",
       "      <td>7.377</td>\n",
       "      <td>5.467</td>\n",
       "      <td>1.057</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.565</td>\n",
       "      <td>SF3B1_K700E_ch</td>\n",
       "      <td>SF3B1_K700E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2.887</td>\n",
       "      <td>1.677</td>\n",
       "      <td>3.050</td>\n",
       "      <td>5.774</td>\n",
       "      <td>5.774</td>\n",
       "      <td>6.954</td>\n",
       "      <td>19.903</td>\n",
       "      <td>17.726</td>\n",
       "      <td>10.009</td>\n",
       "      <td>21.282</td>\n",
       "      <td>...</td>\n",
       "      <td>4.289</td>\n",
       "      <td>2.132</td>\n",
       "      <td>1.014</td>\n",
       "      <td>0.797</td>\n",
       "      <td>3.050</td>\n",
       "      <td>7.827</td>\n",
       "      <td>3.595</td>\n",
       "      <td>11.315</td>\n",
       "      <td>SRSF2_P95H_ch</td>\n",
       "      <td>SRSF2_P95H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3.379</td>\n",
       "      <td>1.816</td>\n",
       "      <td>3.689</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.617</td>\n",
       "      <td>4.430</td>\n",
       "      <td>3.667</td>\n",
       "      <td>4.319</td>\n",
       "      <td>2.734</td>\n",
       "      <td>...</td>\n",
       "      <td>3.979</td>\n",
       "      <td>2.893</td>\n",
       "      <td>1.530</td>\n",
       "      <td>1.299</td>\n",
       "      <td>2.352</td>\n",
       "      <td>7.640</td>\n",
       "      <td>3.944</td>\n",
       "      <td>5.102</td>\n",
       "      <td>SRSF2_P95L_ch</td>\n",
       "      <td>SRSF2_P95L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>3.178</td>\n",
       "      <td>1.853</td>\n",
       "      <td>3.415</td>\n",
       "      <td>3.850</td>\n",
       "      <td>3.850</td>\n",
       "      <td>3.964</td>\n",
       "      <td>16.600</td>\n",
       "      <td>20.550</td>\n",
       "      <td>13.640</td>\n",
       "      <td>18.658</td>\n",
       "      <td>...</td>\n",
       "      <td>3.656</td>\n",
       "      <td>1.068</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.420</td>\n",
       "      <td>2.986</td>\n",
       "      <td>10.174</td>\n",
       "      <td>3.684</td>\n",
       "      <td>11.251</td>\n",
       "      <td>SRSF2_P95R_ch</td>\n",
       "      <td>SRSF2_P95R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>5.285</td>\n",
       "      <td>5.159</td>\n",
       "      <td>6.238</td>\n",
       "      <td>3.879</td>\n",
       "      <td>3.879</td>\n",
       "      <td>3.415</td>\n",
       "      <td>1.761</td>\n",
       "      <td>1.447</td>\n",
       "      <td>1.270</td>\n",
       "      <td>1.692</td>\n",
       "      <td>...</td>\n",
       "      <td>13.711</td>\n",
       "      <td>3.284</td>\n",
       "      <td>2.270</td>\n",
       "      <td>3.036</td>\n",
       "      <td>2.763</td>\n",
       "      <td>9.837</td>\n",
       "      <td>13.844</td>\n",
       "      <td>7.516</td>\n",
       "      <td>TP53_R175H_ch</td>\n",
       "      <td>TP53_R175H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>7.237</td>\n",
       "      <td>10.392</td>\n",
       "      <td>7.881</td>\n",
       "      <td>7.668</td>\n",
       "      <td>7.668</td>\n",
       "      <td>8.440</td>\n",
       "      <td>1.913</td>\n",
       "      <td>2.140</td>\n",
       "      <td>3.311</td>\n",
       "      <td>4.167</td>\n",
       "      <td>...</td>\n",
       "      <td>8.629</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.266</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.579</td>\n",
       "      <td>3.201</td>\n",
       "      <td>9.857</td>\n",
       "      <td>3.914</td>\n",
       "      <td>TP53_R273H_ch</td>\n",
       "      <td>TP53_R273H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows × 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A_101   A_102   A_103  A_1101  A_1102  A_1103   A_201   A_202   A_203  \\\n",
       "0     1.304   1.295   1.163   2.286   2.286   1.618   0.753   0.645   0.238   \n",
       "2     1.018   1.049   0.902   2.498   2.498   1.530   0.807   0.565   0.235   \n",
       "4     1.331   1.437   1.222   2.440   2.440   1.650   0.361   0.321   0.091   \n",
       "6    37.267  47.917  36.111  27.250  27.250  23.808  52.667  55.000  47.400   \n",
       "8     3.837   4.932   4.312   2.104   2.104   2.983   3.226   2.774   3.044   \n",
       "10    2.122   2.566   1.955   1.539   1.539   1.707   6.313   4.497   3.213   \n",
       "12    2.071   2.607   1.932   0.749   0.749   0.972   2.538   1.634   1.243   \n",
       "14   23.380  22.913  25.087   1.678   1.678   1.514  30.909  45.538  32.714   \n",
       "18    0.811   1.196   0.766   2.261   2.261   3.622   0.167   0.085   0.035   \n",
       "20    1.603   1.265   1.485   2.978   2.978   5.565   0.218   0.153   0.078   \n",
       "22    9.050   2.747   9.735   2.858   2.858   2.341   0.646   0.981   2.132   \n",
       "24    3.369   0.999   4.242   1.774   1.774   1.085   0.338   0.375   0.883   \n",
       "26    3.132   0.867   3.889   1.766   1.766   1.168   0.126   0.141   0.459   \n",
       "28    4.969   1.624   6.492   2.457   2.457   1.671   0.296   0.377   1.164   \n",
       "32    2.976   0.878   3.657   0.838   0.838   0.520   0.186   0.217   0.531   \n",
       "34   10.538  17.129  11.839  35.667  35.667  35.333  44.200  37.690  35.938   \n",
       "38    0.787   2.191   0.697   2.177   2.177   2.709   5.803   6.852  10.156   \n",
       "42    0.107   0.120   0.117   1.020   1.020   1.322   4.719   4.029   6.011   \n",
       "44    0.173   0.367   0.142   0.849   0.849   0.994   0.787   1.044   1.035   \n",
       "46    0.834   2.394   0.741   0.642   0.642   0.813   5.985   2.289   4.712   \n",
       "48    0.624   1.880   0.682   0.797   0.797   1.018   4.701   3.997   4.955   \n",
       "50    7.860   1.959  11.349   6.057   6.057   4.909   0.821   0.878   1.070   \n",
       "52    6.096   1.397   7.371   3.530   3.530   3.877   0.190   0.261   0.686   \n",
       "54    3.606   0.898   4.211   3.122   3.122   2.145   0.429   0.285   0.298   \n",
       "56    1.312   1.139   1.314   2.534   2.534   2.208   0.920   0.376   0.052   \n",
       "58    1.997   1.832   1.933   4.071   4.071   2.577  16.810  13.763   9.018   \n",
       "62    8.969   6.388   7.928   1.531   1.531   1.839   5.546   6.663   4.196   \n",
       "64    1.408   1.838   1.311   0.139   0.139   0.093  25.268  18.919  15.070   \n",
       "66   10.487  11.425   8.966  13.886  13.886  11.469   3.408   3.793   5.692   \n",
       "74    7.425  11.104   7.595   0.452   0.452   0.552   5.155   4.956   3.298   \n",
       "76   15.302  13.938  14.158   0.170   0.170   0.166   4.321   4.333   1.923   \n",
       "82    2.389   2.160   2.318   0.292   0.292   0.254   0.938   1.306   2.384   \n",
       "88    7.425  11.104   7.595   0.452   0.452   0.552   5.155   4.956   3.298   \n",
       "94   12.741   9.624  13.538   7.852   7.852   8.903   4.174   3.470   4.222   \n",
       "96    2.377   2.483   1.906   3.220   3.220   5.287   0.026   0.010   0.019   \n",
       "98    2.887   1.677   3.050   5.774   5.774   6.954  19.903  17.726  10.009   \n",
       "100   3.379   1.816   3.689   0.751   0.751   0.617   4.430   3.667   4.319   \n",
       "102   3.178   1.853   3.415   3.850   3.850   3.964  16.600  20.550  13.640   \n",
       "104   5.285   5.159   6.238   3.879   3.879   3.415   1.761   1.447   1.270   \n",
       "106   7.237  10.392   7.881   7.668   7.668   8.440   1.913   2.140   3.311   \n",
       "\n",
       "      A_205  ...   C_501   C_602   C_701   C_702   C_704   C_801   C_802  \\\n",
       "0     0.974  ...   4.538   0.771   0.951   1.073   2.260   2.349   4.492   \n",
       "2     0.752  ...   2.847   0.655   0.804   0.768   2.334   2.087   2.773   \n",
       "4     0.439  ...   6.166   0.513   0.504   0.491   1.427   6.255   8.836   \n",
       "6    60.417  ...  52.000  61.667  53.333  50.000  60.000  45.000  52.500   \n",
       "8     1.188  ...   1.078   1.749   0.881   1.618   3.397   0.660   0.738   \n",
       "10    1.820  ...   0.356   1.624   0.992   1.683   3.454   0.147   0.240   \n",
       "12    0.539  ...   0.362   0.784   0.346   0.699   1.781   0.138   0.248   \n",
       "14   36.703  ...  56.250  32.750  21.231  22.812  55.000  49.000  65.000   \n",
       "18    0.242  ...   3.118   4.558   1.804   0.599   1.615   3.944   2.924   \n",
       "20    0.397  ...   2.903   4.263   1.218   0.336   1.324   4.146   2.917   \n",
       "22    1.750  ...   8.079   3.191   6.357   2.433   4.691   7.322   9.543   \n",
       "24    0.772  ...   6.946   3.513   5.358   2.802   4.899   7.415   5.025   \n",
       "26    0.251  ...   2.785   0.520   1.099   0.321   0.511   2.997   2.356   \n",
       "28    0.822  ...   5.386   0.570   0.371   0.815   1.583   5.327   5.324   \n",
       "32    0.405  ...   4.386   1.297   2.964   0.873   1.432   2.843   3.173   \n",
       "34   32.750  ...   7.169  50.000  47.000  50.000  37.000  23.000   6.772   \n",
       "38    4.253  ...   0.185   4.754   5.046   2.706   2.400   0.271   0.163   \n",
       "42    1.694  ...   0.104   0.391   0.419   0.647   0.188   0.250   0.120   \n",
       "44    0.460  ...   0.005   1.154   0.639   0.507   0.049   0.004   0.003   \n",
       "46    2.949  ...   0.183   1.849   2.528   2.834   0.957   0.282   0.167   \n",
       "48    1.719  ...   0.110   0.519   1.257   1.488   1.125   0.183   0.087   \n",
       "50    1.795  ...   8.034   0.895   2.675   1.053   3.474   7.095   6.775   \n",
       "52    0.527  ...   3.982   0.296   1.012   0.415   0.935   4.070   4.173   \n",
       "54    0.596  ...   3.090   0.154   0.567   0.278   0.493   2.423   2.179   \n",
       "56    0.776  ...   5.807   1.761   0.602   0.613   1.496   3.652   5.966   \n",
       "58    6.278  ...  15.898   7.249   1.921   1.082   8.741   6.631  10.763   \n",
       "62    3.568  ...   3.170   2.660   2.341   3.262   1.067   1.855   2.299   \n",
       "64   12.667  ...  18.549   4.905   2.849   2.368   9.583   9.250  11.820   \n",
       "66    4.234  ...   2.036  14.322  13.655  11.722   7.748   3.396   4.070   \n",
       "74    2.880  ...   0.409  21.000  16.969  12.926   6.380   0.473   0.171   \n",
       "76    2.260  ...   3.642  10.106  13.345  17.314   6.201   2.320   2.200   \n",
       "82    2.653  ...   8.233   0.149   0.076   0.074   3.671   9.010  10.122   \n",
       "88    2.880  ...   0.409  21.000  16.969  12.926   6.380   0.473   0.171   \n",
       "94    2.355  ...   4.795   0.098   0.344   1.068   0.587   2.042   6.131   \n",
       "96    0.027  ...   0.169   5.033   7.377   5.467   1.057   0.519   0.140   \n",
       "98   21.282  ...   4.289   2.132   1.014   0.797   3.050   7.827   3.595   \n",
       "100   2.734  ...   3.979   2.893   1.530   1.299   2.352   7.640   3.944   \n",
       "102  18.658  ...   3.656   1.068   0.525   0.420   2.986  10.174   3.684   \n",
       "104   1.692  ...  13.711   3.284   2.270   3.036   2.763   9.837  13.844   \n",
       "106   4.167  ...   8.629   0.132   0.266   1.034   0.579   3.201   9.857   \n",
       "\n",
       "      C_804      gene_var_gt      gene_var  \n",
       "0     2.495  DNMT3A_P904L_ch  DNMT3A_P904L  \n",
       "2     2.327  DNMT3A_P904Q_ch  DNMT3A_P904Q  \n",
       "4     5.360  DNMT3A_P904R_ch  DNMT3A_P904R  \n",
       "6    38.333  DNMT3A_R320*_ch  DNMT3A_R320*  \n",
       "8     1.085  DNMT3A_R326C_ch  DNMT3A_R326C  \n",
       "10    0.222  DNMT3A_R326G_ch  DNMT3A_R326G  \n",
       "12    0.233  DNMT3A_R326S_ch  DNMT3A_R326S  \n",
       "14   51.250  DNMT3A_R598*_ch  DNMT3A_R598*  \n",
       "18    3.740  DNMT3A_R729G_ch  DNMT3A_R729G  \n",
       "20    4.521  DNMT3A_R729W_ch  DNMT3A_R729W  \n",
       "22    6.963  DNMT3A_R736C_ch  DNMT3A_R736C  \n",
       "24    7.816  DNMT3A_R736G_ch  DNMT3A_R736G  \n",
       "26    3.039  DNMT3A_R736H_ch  DNMT3A_R736H  \n",
       "28    5.934  DNMT3A_R736L_ch  DNMT3A_R736L  \n",
       "32    2.927  DNMT3A_R736S_ch  DNMT3A_R736S  \n",
       "34   20.486  DNMT3A_R771*_ch  DNMT3A_R771*  \n",
       "38    0.326  DNMT3A_R882C_ch  DNMT3A_R882C  \n",
       "42    0.280  DNMT3A_R882H_ch  DNMT3A_R882H  \n",
       "44    0.003  DNMT3A_R882L_ch  DNMT3A_R882L  \n",
       "46    0.322  DNMT3A_R882P_ch  DNMT3A_R882P  \n",
       "48    0.185  DNMT3A_R882S_ch  DNMT3A_R882S  \n",
       "50    8.528  DNMT3A_Y735C_ch  DNMT3A_Y735C  \n",
       "52    5.084  DNMT3A_Y735F_ch  DNMT3A_Y735F  \n",
       "54    2.724  DNMT3A_Y735S_ch  DNMT3A_Y735S  \n",
       "56    4.333     GNB1_K57E_ch     GNB1_K57E  \n",
       "58    8.806    IDH1_R132H_ch    IDH1_R132H  \n",
       "62    2.352    IDH2_R140Q_ch    IDH2_R140Q  \n",
       "64    7.419    IDH2_R172K_ch    IDH2_R172K  \n",
       "66    5.014    JAK2_V617F_ch    JAK2_V617F  \n",
       "74    0.438     KRAS_G12D_ch     KRAS_G12D  \n",
       "76    1.779     KRAS_G12S_ch     KRAS_G12S  \n",
       "82    8.892     MPL_W515L_ch     MPL_W515L  \n",
       "88    0.438     NRAS_G12D_ch     NRAS_G12D  \n",
       "94    2.336   SF3B1_K666N_ch   SF3B1_K666N  \n",
       "96    0.565   SF3B1_K700E_ch   SF3B1_K700E  \n",
       "98   11.315    SRSF2_P95H_ch    SRSF2_P95H  \n",
       "100   5.102    SRSF2_P95L_ch    SRSF2_P95L  \n",
       "102  11.251    SRSF2_P95R_ch    SRSF2_P95R  \n",
       "104   7.516    TP53_R175H_ch    TP53_R175H  \n",
       "106   3.914    TP53_R273H_ch    TP53_R273H  \n",
       "\n",
       "[40 rows x 196 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset to only get predictions for variants which are investigated \n",
    "netmhc_sub2 = netmhc_sub[netmhc_sub['gene_var'].isin(variants_in_ukbb)]\n",
    "netmhc_sub2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to find, for each participant, the best score for each examined CH variant \n",
    "# you take your current df and apply, row by row, the function to get scores for each variant \n",
    "# for the purpose of this, we first need to select MHC columns which are actually in the hla_intersect_list I think \n",
    "# DO NOT use this for sth like MHC heterozygosity tho!!\n",
    "df_hla1_hlas = pd.concat([df_hla1[['Person_ID', 'gene_var', 'VAF', 'ch_status', 'age', 'depth', 'var_depth']], df_hla1[hla_intersect_list]], axis = 1)\n",
    "df_hla1_scores = pd.concat([df_hla1_hlas, df_hla1_hlas.apply(find_best_score_for_all_variants, df=netmhc_sub2, param=param, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person_ID</th>\n",
       "      <th>gene_var</th>\n",
       "      <th>VAF</th>\n",
       "      <th>ch_status</th>\n",
       "      <th>age</th>\n",
       "      <th>depth</th>\n",
       "      <th>var_depth</th>\n",
       "      <th>A_101</th>\n",
       "      <th>A_102</th>\n",
       "      <th>A_103</th>\n",
       "      <th>...</th>\n",
       "      <th>score_SRSF2_P95L</th>\n",
       "      <th>score_SRSF2_P95R</th>\n",
       "      <th>score_TP53_R175H</th>\n",
       "      <th>score_TP53_R273H</th>\n",
       "      <th>het_allele_I_A</th>\n",
       "      <th>het_allele_I_B</th>\n",
       "      <th>het_allele_I_C</th>\n",
       "      <th>sum_class_I</th>\n",
       "      <th>het_all_class_I</th>\n",
       "      <th>het_all_class_I_from_allele</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2812213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.979</td>\n",
       "      <td>3.656</td>\n",
       "      <td>1.761</td>\n",
       "      <td>1.913</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4860169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.525</td>\n",
       "      <td>2.270</td>\n",
       "      <td>0.132</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3381323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.893</td>\n",
       "      <td>1.068</td>\n",
       "      <td>1.468</td>\n",
       "      <td>0.132</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2805252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.299</td>\n",
       "      <td>0.420</td>\n",
       "      <td>3.036</td>\n",
       "      <td>0.132</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1118855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751</td>\n",
       "      <td>1.068</td>\n",
       "      <td>1.761</td>\n",
       "      <td>0.132</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384910</th>\n",
       "      <td>4478244</td>\n",
       "      <td>DNMT3A_R882H</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.420</td>\n",
       "      <td>1.761</td>\n",
       "      <td>0.266</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384911</th>\n",
       "      <td>5660850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.266</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384912</th>\n",
       "      <td>3573995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.525</td>\n",
       "      <td>1.468</td>\n",
       "      <td>0.266</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384913</th>\n",
       "      <td>3025735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520</td>\n",
       "      <td>1.068</td>\n",
       "      <td>1.559</td>\n",
       "      <td>0.132</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384914</th>\n",
       "      <td>1381182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.525</td>\n",
       "      <td>1.761</td>\n",
       "      <td>0.266</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384915 rows × 247 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Person_ID      gene_var       VAF  ch_status  age  depth  var_depth  \\\n",
       "0         2812213           NaN       NaN          0   41    NaN        NaN   \n",
       "1         4860169           NaN       NaN          0   46    NaN        NaN   \n",
       "2         3381323           NaN       NaN          0   52    NaN        NaN   \n",
       "3         2805252           NaN       NaN          0   65    NaN        NaN   \n",
       "4         1118855           NaN       NaN          0   56    NaN        NaN   \n",
       "...           ...           ...       ...        ...  ...    ...        ...   \n",
       "384910    4478244  DNMT3A_R882H  0.022727          1   55   88.0        2.0   \n",
       "384911    5660850           NaN       NaN          0   56    NaN        NaN   \n",
       "384912    3573995           NaN       NaN          0   62    NaN        NaN   \n",
       "384913    3025735           NaN       NaN          0   51    NaN        NaN   \n",
       "384914    1381182           NaN       NaN          0   67    NaN        NaN   \n",
       "\n",
       "        A_101  A_102  A_103  ...  score_SRSF2_P95L  score_SRSF2_P95R  \\\n",
       "0         0.0    0.0    0.0  ...             3.979             3.656   \n",
       "1         2.0    0.0    0.0  ...             0.973             0.525   \n",
       "2         0.0    0.0    0.0  ...             2.893             1.068   \n",
       "3         2.0    0.0    0.0  ...             1.299             0.420   \n",
       "4         0.0    0.0    0.0  ...             0.751             1.068   \n",
       "...       ...    ...    ...  ...               ...               ...   \n",
       "384910    1.0    0.0    0.0  ...             0.973             0.420   \n",
       "384911    1.0    0.0    0.0  ...             0.973             0.525   \n",
       "384912    1.0    0.0    0.0  ...             0.973             0.525   \n",
       "384913    0.0    0.0    0.0  ...             0.520             1.068   \n",
       "384914    1.0    0.0    0.0  ...             0.973             0.525   \n",
       "\n",
       "        score_TP53_R175H  score_TP53_R273H  het_allele_I_A  het_allele_I_B  \\\n",
       "0                  1.761             1.913           False            True   \n",
       "1                  2.270             0.132           False            True   \n",
       "2                  1.468             0.132            True            True   \n",
       "3                  3.036             0.132           False            True   \n",
       "4                  1.761             0.132            True            True   \n",
       "...                  ...               ...             ...             ...   \n",
       "384910             1.761             0.266            True            True   \n",
       "384911             0.995             0.266            True            True   \n",
       "384912             1.468             0.266            True            True   \n",
       "384913             1.559             0.132            True            True   \n",
       "384914             1.761             0.266            True            True   \n",
       "\n",
       "        het_allele_I_C  sum_class_I  het_all_class_I  \\\n",
       "0                 True          6.0            False   \n",
       "1                 True          6.0            False   \n",
       "2                 True          6.0             True   \n",
       "3                 True          6.0            False   \n",
       "4                 True          6.0             True   \n",
       "...                ...          ...              ...   \n",
       "384910            True          6.0             True   \n",
       "384911            True          6.0             True   \n",
       "384912            True          6.0             True   \n",
       "384913            True          6.0             True   \n",
       "384914            True          6.0             True   \n",
       "\n",
       "        het_all_class_I_from_allele  \n",
       "0                             False  \n",
       "1                             False  \n",
       "2                              True  \n",
       "3                             False  \n",
       "4                              True  \n",
       "...                             ...  \n",
       "384910                         True  \n",
       "384911                         True  \n",
       "384912                         True  \n",
       "384913                         True  \n",
       "384914                         True  \n",
       "\n",
       "[384915 rows x 247 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the df \n",
    "# add extra columns (read depth etc + MHC data)\n",
    "df_hla1_scores_added = pd.concat([df_hla1_scores, df_hla1[['het_allele_I_A', 'het_allele_I_B', 'het_allele_I_C', 'sum_class_I', 'het_all_class_I', 'het_all_class_I_from_allele']]], axis = 1)\n",
    "df_hla1_scores_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a file (this is already usable for further analysis)\n",
    "df_hla1_scores_added.to_csv('/Users/barbarawalkowiak/Desktop/msc_thesis/results/dataframes/20240907_netmhc1_scores_for_all_var.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO RUN THE FOLLOWING CELLS TO ADD LABELS, IF YOU HAVE ALREADY SAVED THE DATAFRAMES ABOVE, RUN THIS CELL\n",
    "df_hla1_scores_added = pd.read_csv('/Users/barbarawalkowiak/Desktop/msc_thesis/results/dataframes/20240907_netmhc1_scores_for_all_var.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add label (top / bottom half of binding scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the dataframe to only include gene_var, Person ID and scores \n",
    "scores_col = [col for col in df_hla1_scores_added.columns if col.startswith('score_')]\n",
    "df_hla1_scores_sub = pd.concat([df_hla1_scores_added[['Person_ID', 'gene_var', 'VAF', 'var_depth']], df_hla1_scores_added[scores_col]], axis = 1)\n",
    "\n",
    "# melt the dataframe \n",
    "df_hla1_scores_sub_melted = pd.melt(df_hla1_scores_sub, id_vars = ['Person_ID', 'gene_var', 'VAF', 'var_depth'])\n",
    "\n",
    "# add a column which has the name of the variant formatted)\n",
    "df_hla1_scores_sub_melted['CH_variant'] = df_hla1_scores_sub_melted['variable'].str[6:]\n",
    "\n",
    "# add a column to indicate CH status (either carrier of the variant the score is for, or non-carrier, even if has CH driven by a different variant)\n",
    "df_hla1_scores_sub_melted['CH_status'] = np.where(df_hla1_scores_sub_melted['gene_var'] == df_hla1_scores_sub_melted['CH_variant'], 1, 0)\n",
    "\n",
    "# binding score in the format of -1*log10(%Rank_EL)\n",
    "df_hla1_scores_sub_melted['log_score'] = -1 * np.log10(df_hla1_scores_sub_melted['value'])\n",
    "\n",
    "# add median score for each variant and then order them by median \n",
    "df_hla1_scores_sub_melted['median_score'] = df_hla1_scores_sub_melted.groupby('CH_variant')['log_score'].transform('median')\n",
    "\n",
    "# convert to categories \n",
    "df_hla1_scores_sub_melted['gene_var'] = df_hla1_scores_sub_melted['gene_var'].astype('category') \n",
    "df_hla1_scores_sub_melted['CH_variant'] = df_hla1_scores_sub_melted['CH_variant'].astype('category') # make sure you convert this to category first of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add group (split participants with values equal to the median)\n",
    "\n",
    "# there is quite a lot of people who have the score == median score \n",
    "# I am splitting this group so that the number of people with top / bottom is the same: here, each person whose score == median is assigned at random top or bottom \n",
    "variants = df_hla1_scores_sub_melted.CH_variant.unique().tolist()\n",
    "\n",
    "for var in variants:\n",
    "\n",
    "    # select df with variant \n",
    "    df_variant = df_hla1_scores_sub_melted[df_hla1_scores_sub_melted['CH_variant'] == var]\n",
    "    \n",
    "    # get the median \n",
    "    median_score = df_variant['log_score'].median()\n",
    "    \n",
    "    # find median values \n",
    "    median_values = df_variant[df_variant['log_score'] == df_variant['median_score']]\n",
    "    \n",
    "    # assign top / bottom if above or below median \n",
    "    below_median = df_variant[df_variant['log_score'] < median_score]\n",
    "    above_median = df_variant[df_variant['log_score'] > median_score]\n",
    "    \n",
    "    # figure out how many observations you need with median values to top / bottom half\n",
    "    half_length = len(df_variant) // 2\n",
    "    num_bottom_needed = half_length - len(below_median)\n",
    "    num_top_needed = len(median_values) - num_bottom_needed\n",
    "    \n",
    "    # assign values equal to median to top or bottom\n",
    "    shuffled_median_values = median_values.sample(frac=1)\n",
    "    bottom_half_median = shuffled_median_values.iloc[:num_bottom_needed]\n",
    "    top_half_median = shuffled_median_values.iloc[num_bottom_needed:]\n",
    "    \n",
    "    # assign groups\n",
    "    df_hla1_scores_sub_melted.loc[below_median.index, 'group'] = 'bottom half'\n",
    "    df_hla1_scores_sub_melted.loc[above_median.index, 'group'] = 'top half'\n",
    "    df_hla1_scores_sub_melted.loc[bottom_half_median.index, 'group'] = 'bottom half'\n",
    "    df_hla1_scores_sub_melted.loc[top_half_median.index, 'group'] = 'top half'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified saving labels\n",
    "\n",
    "# save to a file (this is already usable for further analysis)\n",
    "df_hla1_scores_sub_melted.to_csv('/Users/barbarawalkowiak/Desktop/msc_thesis/results/dataframes/20240907_netmhc1_scores_for_all_var_with_labels.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load binding predictions for MHC I from PRIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of alleles for which predictions are available (NetMHC): 194\n",
      "Number of HLA alleles which have been identified in the UK BioBank: 215\n",
      "Number of unique variants I have predictions for (NetMHC): 54\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import NetMHC scores  \n",
    "pred_file_prime = '/Users/barbarawalkowiak/Desktop/msc_thesis/PRIME_out/scores/20240716_PRIME_HLA_UKBB_with_affinities_bestscores_allvariants.csv' # best EL rank, nr of weak and strong binders (I don't have affinity predictions and I am afraid this will have to do)\n",
    "pred_filename_prime = pred_file_prime.split('/')[2].split('.')[0] # identify file name \n",
    "pred_method_prime = pred_file_prime.split('_out')[0] # identify method used to obtain predictions\n",
    "\n",
    "# load the csv\n",
    "prime = pd.read_csv(pred_file_prime) # load the csv \n",
    "prime = prime.rename(columns={'allele': 'HLA'})\n",
    "\n",
    "# specify HLA allele naming format \n",
    "prime_col = prime.HLA\n",
    "prime_formatted = prime_col.apply(transform_format_prime)\n",
    "prime = pd.concat([prime, prime_formatted.rename('HLA_formatted')], axis = 1)\n",
    "\n",
    "# Replace STOP with *\n",
    "prime['variant'] = prime['variant'].str.replace('STOP', '*')\n",
    "\n",
    "# rename column from min_rank to '%Rank_EL' to keep it consistent with NetMHC\n",
    "prime = prime.rename(columns={'min_rank': '%Rank_EL'})\n",
    "\n",
    "# select required columns and sor values \n",
    "prime = prime[['HLA_formatted', '%Rank_EL', 'sum_peptides_below_05', 'sum_peptides_below_2', 'gene', 'variant', 'genotype']]\n",
    "prime = prime.sort_values(by=['HLA_formatted', 'gene', 'variant', 'genotype'])\n",
    "\n",
    "# identify gene variants \n",
    "prime['gene_var_gt'] = prime['gene'] + '_' + prime['variant'] + '_' + prime['genotype'] # add complete genotype data\n",
    "prime['gene_var'] = prime['gene'] + '_' + prime['variant']\n",
    "prime['varID'] = prime['gene'] + ' ' + prime['variant'] # this is a column where the variant ID is in the same format as in the CH cases dataframe\n",
    "scores_prime = prime[['HLA_formatted', '%Rank_EL', 'varID', 'gene_var', 'gene_var_gt']] # select columns of interest (realistically I only want minimum %EL rank anyway)\n",
    "\n",
    "# Print the results \n",
    "print('Number of alleles for which predictions are available (NetMHC):', len(prime.HLA_formatted.unique()))\n",
    "\n",
    "# Find MHC alleles which have been typed in the UKBB\n",
    "hla_ukbb = df_hla1.filter(regex='\\d').columns # HLA from all UKBB\n",
    "print('Number of HLA alleles which have been identified in the UK BioBank:', len(hla_ukbb))\n",
    "\n",
    "# Now look at variants\n",
    "print('Number of unique variants I have predictions for (NetMHC):',  len(prime.gene_var.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variants identified in the UKBB from CH screening: 40\n",
      "Number or variants I have predictions for (PRIME): 54\n",
      "List of variants identified in UKBB: ['DNMT3A_P904L', 'DNMT3A_P904Q', 'DNMT3A_P904R', 'DNMT3A_R320*', 'DNMT3A_R326C', 'DNMT3A_R326G', 'DNMT3A_R326S', 'DNMT3A_R598*', 'DNMT3A_R729G', 'DNMT3A_R729W', 'DNMT3A_R736C', 'DNMT3A_R736G', 'DNMT3A_R736H', 'DNMT3A_R736L', 'DNMT3A_R736S', 'DNMT3A_R771*', 'DNMT3A_R882C', 'DNMT3A_R882H', 'DNMT3A_R882L', 'DNMT3A_R882P', 'DNMT3A_R882S', 'DNMT3A_Y735C', 'DNMT3A_Y735F', 'DNMT3A_Y735S', 'GNB1_K57E', 'IDH1_R132H', 'IDH2_R140Q', 'IDH2_R172K', 'JAK2_V617F', 'KRAS_G12D', 'KRAS_G12S', 'MPL_W515L', 'NRAS_G12D', 'SF3B1_K666N', 'SF3B1_K700E', 'SRSF2_P95H', 'SRSF2_P95L', 'SRSF2_P95R', 'TP53_R175H', 'TP53_R273H']\n",
      "List of variants with PRIME preds: ['DNMT3A_P904L', 'DNMT3A_P904Q', 'DNMT3A_P904R', 'DNMT3A_R320*', 'DNMT3A_R326C', 'DNMT3A_R326G', 'DNMT3A_R326S', 'DNMT3A_R598*', 'DNMT3A_R598G', 'DNMT3A_R729G', 'DNMT3A_R729W', 'DNMT3A_R736C', 'DNMT3A_R736G', 'DNMT3A_R736H', 'DNMT3A_R736L', 'DNMT3A_R736P', 'DNMT3A_R736S', 'DNMT3A_R771*', 'DNMT3A_R771G', 'DNMT3A_R882C', 'DNMT3A_R882G', 'DNMT3A_R882H', 'DNMT3A_R882L', 'DNMT3A_R882P', 'DNMT3A_R882S', 'DNMT3A_Y735C', 'DNMT3A_Y735F', 'DNMT3A_Y735S', 'GNB1_K57E', 'IDH1_R132H', 'IDH2_R140L', 'IDH2_R140Q', 'IDH2_R172K', 'JAK2_V617F', 'KIT_D816G', 'KIT_D816V', 'KRAS_G12A', 'KRAS_G12D', 'KRAS_G12S', 'KRAS_G12V', 'MPL_W515*', 'MPL_W515L', 'NRAS_G12A', 'NRAS_G12C', 'NRAS_G12D', 'NRAS_G12S', 'NRAS_G12V', 'SF3B1_K666N', 'SF3B1_K700E', 'SRSF2_P95H', 'SRSF2_P95L', 'SRSF2_P95R', 'TP53_R175H', 'TP53_R273H']\n"
     ]
    }
   ],
   "source": [
    "print('Number of variants identified in the UKBB from CH screening:', len(df_hla1.gene_var.unique())-1) # NB this list also includes 'NaN' that's why its -1\n",
    "print('Number or variants I have predictions for (PRIME):',  len(prime.gene_var.unique()))\n",
    "\n",
    "variants_in_ukbb = df_hla1.gene_var.unique().tolist()\n",
    "variants_in_ukbb = [x for x in variants_in_ukbb if str(x) != 'nan']\n",
    "print('List of variants identified in UKBB:', sorted(variants_in_ukbb))\n",
    "print('List of variants with PRIME preds:',  sorted(prime.gene_var.unique())) # there is more because I also made predictions for variants which ended up not being common enough "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_var_gt</th>\n",
       "      <th>A_101</th>\n",
       "      <th>A_102</th>\n",
       "      <th>A_103</th>\n",
       "      <th>A_1101</th>\n",
       "      <th>A_1102</th>\n",
       "      <th>A_1103</th>\n",
       "      <th>A_201</th>\n",
       "      <th>A_202</th>\n",
       "      <th>A_203</th>\n",
       "      <th>...</th>\n",
       "      <th>C_403</th>\n",
       "      <th>C_407</th>\n",
       "      <th>C_501</th>\n",
       "      <th>C_602</th>\n",
       "      <th>C_701</th>\n",
       "      <th>C_702</th>\n",
       "      <th>C_704</th>\n",
       "      <th>C_801</th>\n",
       "      <th>C_802</th>\n",
       "      <th>C_804</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNMT3A_P904L_ch</td>\n",
       "      <td>1.490</td>\n",
       "      <td>1.490</td>\n",
       "      <td>1.490</td>\n",
       "      <td>1.167</td>\n",
       "      <td>1.210</td>\n",
       "      <td>1.167</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DNMT3A_P904L_refseq</td>\n",
       "      <td>2.985</td>\n",
       "      <td>2.985</td>\n",
       "      <td>2.985</td>\n",
       "      <td>1.796</td>\n",
       "      <td>1.846</td>\n",
       "      <td>1.796</td>\n",
       "      <td>1.138</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.513</td>\n",
       "      <td>1.678</td>\n",
       "      <td>0.455</td>\n",
       "      <td>1.026</td>\n",
       "      <td>0.259</td>\n",
       "      <td>1.428</td>\n",
       "      <td>1.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DNMT3A_P904Q_ch</td>\n",
       "      <td>2.544</td>\n",
       "      <td>2.544</td>\n",
       "      <td>2.544</td>\n",
       "      <td>3.406</td>\n",
       "      <td>2.601</td>\n",
       "      <td>3.406</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.019</td>\n",
       "      <td>...</td>\n",
       "      <td>1.075</td>\n",
       "      <td>0.434</td>\n",
       "      <td>1.044</td>\n",
       "      <td>0.082</td>\n",
       "      <td>1.299</td>\n",
       "      <td>0.440</td>\n",
       "      <td>1.945</td>\n",
       "      <td>0.311</td>\n",
       "      <td>1.475</td>\n",
       "      <td>1.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DNMT3A_P904Q_refseq</td>\n",
       "      <td>2.985</td>\n",
       "      <td>2.985</td>\n",
       "      <td>2.985</td>\n",
       "      <td>1.796</td>\n",
       "      <td>1.846</td>\n",
       "      <td>1.796</td>\n",
       "      <td>1.138</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.513</td>\n",
       "      <td>1.678</td>\n",
       "      <td>0.455</td>\n",
       "      <td>1.026</td>\n",
       "      <td>0.259</td>\n",
       "      <td>1.428</td>\n",
       "      <td>1.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DNMT3A_P904R_ch</td>\n",
       "      <td>2.846</td>\n",
       "      <td>2.846</td>\n",
       "      <td>2.846</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.469</td>\n",
       "      <td>1.726</td>\n",
       "      <td>0.514</td>\n",
       "      <td>1.859</td>\n",
       "      <td>1.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>SRSF2_P95R_refseq</td>\n",
       "      <td>7.313</td>\n",
       "      <td>7.313</td>\n",
       "      <td>7.313</td>\n",
       "      <td>4.763</td>\n",
       "      <td>7.841</td>\n",
       "      <td>4.763</td>\n",
       "      <td>11.579</td>\n",
       "      <td>11.259</td>\n",
       "      <td>12.816</td>\n",
       "      <td>...</td>\n",
       "      <td>5.217</td>\n",
       "      <td>5.758</td>\n",
       "      <td>5.444</td>\n",
       "      <td>1.548</td>\n",
       "      <td>1.109</td>\n",
       "      <td>0.456</td>\n",
       "      <td>1.007</td>\n",
       "      <td>1.956</td>\n",
       "      <td>8.023</td>\n",
       "      <td>8.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>TP53_R175H_ch</td>\n",
       "      <td>2.672</td>\n",
       "      <td>2.672</td>\n",
       "      <td>2.672</td>\n",
       "      <td>4.340</td>\n",
       "      <td>5.084</td>\n",
       "      <td>4.340</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.555</td>\n",
       "      <td>...</td>\n",
       "      <td>4.220</td>\n",
       "      <td>3.669</td>\n",
       "      <td>5.319</td>\n",
       "      <td>0.740</td>\n",
       "      <td>1.556</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.795</td>\n",
       "      <td>3.628</td>\n",
       "      <td>8.944</td>\n",
       "      <td>8.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>TP53_R175H_refseq</td>\n",
       "      <td>4.638</td>\n",
       "      <td>4.638</td>\n",
       "      <td>4.638</td>\n",
       "      <td>1.639</td>\n",
       "      <td>1.989</td>\n",
       "      <td>1.639</td>\n",
       "      <td>1.332</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.604</td>\n",
       "      <td>...</td>\n",
       "      <td>10.332</td>\n",
       "      <td>8.958</td>\n",
       "      <td>13.608</td>\n",
       "      <td>1.888</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.595</td>\n",
       "      <td>2.867</td>\n",
       "      <td>13.566</td>\n",
       "      <td>18.073</td>\n",
       "      <td>18.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>TP53_R273H_ch</td>\n",
       "      <td>5.004</td>\n",
       "      <td>5.004</td>\n",
       "      <td>5.004</td>\n",
       "      <td>5.790</td>\n",
       "      <td>4.049</td>\n",
       "      <td>5.790</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.717</td>\n",
       "      <td>1.059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806</td>\n",
       "      <td>1.050</td>\n",
       "      <td>2.372</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.078</td>\n",
       "      <td>1.387</td>\n",
       "      <td>3.657</td>\n",
       "      <td>3.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>TP53_R273H_refseq</td>\n",
       "      <td>12.906</td>\n",
       "      <td>12.906</td>\n",
       "      <td>12.906</td>\n",
       "      <td>4.823</td>\n",
       "      <td>5.589</td>\n",
       "      <td>4.823</td>\n",
       "      <td>1.913</td>\n",
       "      <td>1.778</td>\n",
       "      <td>2.902</td>\n",
       "      <td>...</td>\n",
       "      <td>2.165</td>\n",
       "      <td>2.760</td>\n",
       "      <td>5.363</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.779</td>\n",
       "      <td>4.802</td>\n",
       "      <td>7.760</td>\n",
       "      <td>7.760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             gene_var_gt   A_101   A_102   A_103  A_1101  A_1102  A_1103  \\\n",
       "0        DNMT3A_P904L_ch   1.490   1.490   1.490   1.167   1.210   1.167   \n",
       "1    DNMT3A_P904L_refseq   2.985   2.985   2.985   1.796   1.846   1.796   \n",
       "2        DNMT3A_P904Q_ch   2.544   2.544   2.544   3.406   2.601   3.406   \n",
       "3    DNMT3A_P904Q_refseq   2.985   2.985   2.985   1.796   1.846   1.796   \n",
       "4        DNMT3A_P904R_ch   2.846   2.846   2.846   0.688   0.756   0.688   \n",
       "..                   ...     ...     ...     ...     ...     ...     ...   \n",
       "103    SRSF2_P95R_refseq   7.313   7.313   7.313   4.763   7.841   4.763   \n",
       "104        TP53_R175H_ch   2.672   2.672   2.672   4.340   5.084   4.340   \n",
       "105    TP53_R175H_refseq   4.638   4.638   4.638   1.639   1.989   1.639   \n",
       "106        TP53_R273H_ch   5.004   5.004   5.004   5.790   4.049   5.790   \n",
       "107    TP53_R273H_refseq  12.906  12.906  12.906   4.823   5.589   4.823   \n",
       "\n",
       "      A_201   A_202   A_203  ...   C_403  C_407   C_501  C_602  C_701  C_702  \\\n",
       "0     0.105   0.034   0.019  ...   0.319  0.100   0.560  0.231  0.461  0.192   \n",
       "1     1.138   0.265   0.172  ...   0.255  0.080   0.706  0.513  1.678  0.455   \n",
       "2     0.093   0.040   0.019  ...   1.075  0.434   1.044  0.082  1.299  0.440   \n",
       "3     1.138   0.265   0.172  ...   0.255  0.080   0.706  0.513  1.678  0.455   \n",
       "4     0.073   0.031   0.018  ...   0.798  0.609   0.922  0.049  0.719  0.469   \n",
       "..      ...     ...     ...  ...     ...    ...     ...    ...    ...    ...   \n",
       "103  11.579  11.259  12.816  ...   5.217  5.758   5.444  1.548  1.109  0.456   \n",
       "104   0.501   0.250   0.555  ...   4.220  3.669   5.319  0.740  1.556  0.401   \n",
       "105   1.332   0.625   1.604  ...  10.332  8.958  13.608  1.888  0.741  0.595   \n",
       "106   0.764   0.717   1.059  ...   0.806  1.050   2.372  0.029  0.073  0.260   \n",
       "107   1.913   1.778   2.902  ...   2.165  2.760   5.363  0.089  0.214  0.890   \n",
       "\n",
       "     C_704   C_801   C_802   C_804  \n",
       "0    0.484   0.250   0.976   0.976  \n",
       "1    1.026   0.259   1.428   1.428  \n",
       "2    1.945   0.311   1.475   1.475  \n",
       "3    1.026   0.259   1.428   1.428  \n",
       "4    1.726   0.514   1.859   1.859  \n",
       "..     ...     ...     ...     ...  \n",
       "103  1.007   1.956   8.023   8.023  \n",
       "104  0.795   3.628   8.944   8.944  \n",
       "105  2.867  13.566  18.073  18.073  \n",
       "106  0.078   1.387   3.657   3.657  \n",
       "107  0.779   4.802   7.760   7.760  \n",
       "\n",
       "[108 rows x 195 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# create a suitably formatted NetMHC df \n",
    "param = '%Rank_EL'\n",
    "prime_sub = prime[['HLA_formatted', 'gene_var_gt', param]]\n",
    "prime_sub_wide = pd.pivot(prime_sub, index='gene_var_gt', columns='HLA_formatted', values=param)\n",
    "prime_sub_wide = prime_sub_wide.reset_index() # this is to make sure that you have the gene_var column in there too \n",
    "prime_sub_wide.columns = map(transform_format_prime, prime_sub_wide.columns)\n",
    "prime_sub_wide\n",
    "\n",
    "# it makes sense that we have 104 rows bc 2 * 54 variants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a list of HLA alleles genotyped in the UKBB for which predictions are available\n",
    "hla_intersect = prime_sub_wide.columns[prime_sub_wide.columns.isin(hla_ukbb)] # HLA in the UKBB which I have predictions for \n",
    "hla_intersect_list = hla_intersect.tolist() # 194 alleles \n",
    "\n",
    "# create the prediction dataset \n",
    "prime_sub = prime_sub_wide[hla_intersect_list + prime_sub_wide.columns[prime_sub_wide.columns.str.contains('gene_var')].tolist()] # subset netmhc so you only have alleles which are in the UKBB, also 194\n",
    "prime_sub = prime_sub[prime_sub['gene_var_gt'].str.contains('_ch', regex=True)] # retain CH scores only \n",
    "prime_sub['gene_var'] = prime_sub['gene_var_gt'].str.replace('_ch', '') # remove the ch / refseq annotation\n",
    "prime_sub['gene_var'] = prime_sub['gene_var'].str.replace('_refseq', '') # remove refseq if present \n",
    "prime_sub = prime_sub[prime_sub['gene_var'].isin(variants_in_ukbb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to find, for each participant, the best score for each examined CH variant \n",
    "# you take your current df and apply, row by row, the function to get scores for each variant \n",
    "# for the purpose of this, we first need to select MHC columns which are actually in the hla_intersect_list I think \n",
    "# DO NOT use this for sth like MHC heterozygosity tho!!\n",
    "df_hla1_hlas = pd.concat([df_hla1[['Person_ID', 'gene_var', 'VAF', 'ch_status', 'age', 'depth', 'var_depth']], df_hla1[hla_intersect_list]], axis = 1)\n",
    "df_hla1_scores = pd.concat([df_hla1_hlas, df_hla1_hlas.apply(find_best_score_for_all_variants, df=prime_sub, param=param, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person_ID</th>\n",
       "      <th>gene_var</th>\n",
       "      <th>VAF</th>\n",
       "      <th>ch_status</th>\n",
       "      <th>age</th>\n",
       "      <th>depth</th>\n",
       "      <th>var_depth</th>\n",
       "      <th>A_101</th>\n",
       "      <th>A_102</th>\n",
       "      <th>A_103</th>\n",
       "      <th>...</th>\n",
       "      <th>score_TP53_R175H</th>\n",
       "      <th>score_TP53_R273H</th>\n",
       "      <th>het_allele_I_A</th>\n",
       "      <th>het_allele_I_B</th>\n",
       "      <th>het_allele_I_C</th>\n",
       "      <th>sum_class_I</th>\n",
       "      <th>het_all_class_I</th>\n",
       "      <th>het_all_class_I_from_allele</th>\n",
       "      <th>depth</th>\n",
       "      <th>var_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2812213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.764</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4860169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.029</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3381323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.029</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2805252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.029</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1118855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.029</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384910</th>\n",
       "      <td>4478244</td>\n",
       "      <td>DNMT3A_R882H</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.073</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384911</th>\n",
       "      <td>5660850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.073</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384912</th>\n",
       "      <td>3573995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.073</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384913</th>\n",
       "      <td>3025735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.029</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384914</th>\n",
       "      <td>1381182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.073</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384915 rows × 249 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Person_ID      gene_var       VAF  ch_status  age  depth  var_depth  \\\n",
       "0         2812213           NaN       NaN          0   41    NaN        NaN   \n",
       "1         4860169           NaN       NaN          0   46    NaN        NaN   \n",
       "2         3381323           NaN       NaN          0   52    NaN        NaN   \n",
       "3         2805252           NaN       NaN          0   65    NaN        NaN   \n",
       "4         1118855           NaN       NaN          0   56    NaN        NaN   \n",
       "...           ...           ...       ...        ...  ...    ...        ...   \n",
       "384910    4478244  DNMT3A_R882H  0.022727          1   55   88.0        2.0   \n",
       "384911    5660850           NaN       NaN          0   56    NaN        NaN   \n",
       "384912    3573995           NaN       NaN          0   62    NaN        NaN   \n",
       "384913    3025735           NaN       NaN          0   51    NaN        NaN   \n",
       "384914    1381182           NaN       NaN          0   67    NaN        NaN   \n",
       "\n",
       "        A_101  A_102  A_103  ...  score_TP53_R175H  score_TP53_R273H  \\\n",
       "0         0.0    0.0    0.0  ...             0.501             0.764   \n",
       "1         2.0    0.0    0.0  ...             0.740             0.029   \n",
       "2         0.0    0.0    0.0  ...             0.385             0.029   \n",
       "3         2.0    0.0    0.0  ...             0.401             0.029   \n",
       "4         0.0    0.0    0.0  ...             0.501             0.029   \n",
       "...       ...    ...    ...  ...               ...               ...   \n",
       "384910    1.0    0.0    0.0  ...             0.401             0.073   \n",
       "384911    1.0    0.0    0.0  ...             0.281             0.073   \n",
       "384912    1.0    0.0    0.0  ...             0.385             0.073   \n",
       "384913    0.0    0.0    0.0  ...             0.740             0.029   \n",
       "384914    1.0    0.0    0.0  ...             0.501             0.073   \n",
       "\n",
       "        het_allele_I_A  het_allele_I_B  het_allele_I_C  sum_class_I  \\\n",
       "0                False            True            True          6.0   \n",
       "1                False            True            True          6.0   \n",
       "2                 True            True            True          6.0   \n",
       "3                False            True            True          6.0   \n",
       "4                 True            True            True          6.0   \n",
       "...                ...             ...             ...          ...   \n",
       "384910            True            True            True          6.0   \n",
       "384911            True            True            True          6.0   \n",
       "384912            True            True            True          6.0   \n",
       "384913            True            True            True          6.0   \n",
       "384914            True            True            True          6.0   \n",
       "\n",
       "        het_all_class_I  het_all_class_I_from_allele  depth  var_depth  \n",
       "0                 False                        False    NaN        NaN  \n",
       "1                 False                        False    NaN        NaN  \n",
       "2                  True                         True    NaN        NaN  \n",
       "3                 False                        False    NaN        NaN  \n",
       "4                  True                         True    NaN        NaN  \n",
       "...                 ...                          ...    ...        ...  \n",
       "384910             True                         True   88.0        2.0  \n",
       "384911             True                         True    NaN        NaN  \n",
       "384912             True                         True    NaN        NaN  \n",
       "384913             True                         True    NaN        NaN  \n",
       "384914             True                         True    NaN        NaN  \n",
       "\n",
       "[384915 rows x 249 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the df (just check it looks okay)\n",
    "# add extra columns (read depth etc + MHC data)\n",
    "df_hla1_scores_added = pd.concat([df_hla1_scores, df_hla1[['het_allele_I_A', 'het_allele_I_B', 'het_allele_I_C', 'sum_class_I', 'het_all_class_I', 'het_all_class_I_from_allele']]], axis = 1)\n",
    "df_hla1_scores_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a file (this is already usable for further analysis)\n",
    "df_hla1_scores_added.to_csv('/Users/barbarawalkowiak/Desktop/msc_thesis/results/dataframes/20240907_prime_scores_for_all_var.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR LABELS, READ THIS IN (in case kernel crashes etc.)\n",
    "df_hla1_scores_added = pd.read_csv('/Users/barbarawalkowiak/Desktop/msc_thesis/results/dataframes/20240907_prime_scores_for_all_var.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add labels (top / bottom half of binding scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add median scores\n",
    "\n",
    "# subset the dataframe to only include gene_var, Person ID and scores \n",
    "scores_col = [col for col in df_hla1_scores_added_dp.columns if col.startswith('score_')]\n",
    "df_hla1_scores_sub = pd.concat([df_hla1_scores_added_dp[['Person_ID', 'gene_var', 'VAF', 'var_depth']], df_hla1_scores_added_dp[scores_col]], axis = 1)\n",
    "\n",
    "# melt the dataframe \n",
    "df_hla1_scores_sub_melted = pd.melt(df_hla1_scores_sub, id_vars = ['gene_var', 'Person_ID', 'VAF', 'var_depth'])\n",
    "\n",
    "# add a column which has the name of the variant (nicely formatted)\n",
    "df_hla1_scores_sub_melted['CH_variant'] = df_hla1_scores_sub_melted['variable'].str[6:]\n",
    "\n",
    "# add a column to indicate CH status (either carrier of the variant the score is for, or non-carrier, even if have CH driven by sth else)\n",
    "df_hla1_scores_sub_melted['CH_status'] = np.where(df_hla1_scores_sub_melted['gene_var'] == df_hla1_scores_sub_melted['CH_variant'].replace(), 1, 0)\n",
    "\n",
    "# you want the %Rank_EL to be in the format of -1*log10(%Rank_EL)\n",
    "df_hla1_scores_sub_melted['log_score'] = -1 * np.log10(df_hla1_scores_sub_melted['value'])\n",
    "\n",
    "# add median score for each variant and then order them by median \n",
    "df_hla1_scores_sub_melted['median_score'] = df_hla1_scores_sub_melted.groupby('CH_variant')['log_score'].transform('median')\n",
    "\n",
    "# convert to categories \n",
    "df_hla1_scores_sub_melted['gene_var'] = df_hla1_scores_sub_melted['gene_var'].astype('category') \n",
    "df_hla1_scores_sub_melted['CH_variant'] = df_hla1_scores_sub_melted['CH_variant'].astype('category') # make sure you convert this to category first of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add group (split participants with values equal to the median)\n",
    "\n",
    "# there is quite a lot of people who have the score == median score \n",
    "# I am splitting this group so that the number of people with top / bottom is the same: here, each person whose score == median is assigned at random top or bottom \n",
    "variants = df_hla1_scores_sub_melted.CH_variant.unique().tolist()\n",
    "\n",
    "for var in variants:\n",
    "\n",
    "    # select df with variant \n",
    "    df_variant = df_hla1_scores_sub_melted[df_hla1_scores_sub_melted['CH_variant'] == var]\n",
    "    \n",
    "    # get the median \n",
    "    median_score = df_variant['log_score'].median()\n",
    "    \n",
    "    # find median values \n",
    "    median_values = df_variant[df_variant['log_score'] == df_variant['median_score']]\n",
    "    \n",
    "    # assign top / bottom if above or below median \n",
    "    below_median = df_variant[df_variant['log_score'] < median_score]\n",
    "    above_median = df_variant[df_variant['log_score'] > median_score]\n",
    "    \n",
    "    # figure out how many observations you need with median values to top / bottom half\n",
    "    half_length = len(df_variant) // 2\n",
    "    num_bottom_needed = half_length - len(below_median)\n",
    "    num_top_needed = len(median_values) - num_bottom_needed\n",
    "    \n",
    "    # assign values equal to median to top or bottom\n",
    "    shuffled_median_values = median_values.sample(frac=1)\n",
    "    bottom_half_median = shuffled_median_values.iloc[:num_bottom_needed]\n",
    "    top_half_median = shuffled_median_values.iloc[num_bottom_needed:]\n",
    "    \n",
    "    # assign groups\n",
    "    df_hla1_scores_sub_melted.loc[below_median.index, 'group'] = 'bottom half'\n",
    "    df_hla1_scores_sub_melted.loc[above_median.index, 'group'] = 'top half'\n",
    "    df_hla1_scores_sub_melted.loc[bottom_half_median.index, 'group'] = 'bottom half'\n",
    "    df_hla1_scores_sub_melted.loc[top_half_median.index, 'group'] = 'top half'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# save to csv file\n",
    "# save to a file (this is already usable for further analysis)\n",
    "df_hla1_scores_sub_melted.to_csv('/Users/barbarawalkowiak/Desktop/msc_thesis/results/dataframes/20240907_prime_scores_for_all_var_with_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative scores\n",
    "\n",
    "- Binding affinity \n",
    "\n",
    "- DAI (based on %EL rank)\n",
    "\n",
    "- DAI (based on binding affinity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'netmhc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 1 get binding affinities \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# create a suitably formatted NetMHC df \u001b[39;00m\n\u001b[1;32m      4\u001b[0m param \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAff_nM\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m netmhc_sub \u001b[38;5;241m=\u001b[39m \u001b[43mnetmhc\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHLA_formatted\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgene_var_gt\u001b[39m\u001b[38;5;124m'\u001b[39m, param]]\n\u001b[1;32m      6\u001b[0m netmhc_sub_wide \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mpivot(netmhc_sub, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgene_var_gt\u001b[39m\u001b[38;5;124m'\u001b[39m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHLA_formatted\u001b[39m\u001b[38;5;124m'\u001b[39m, values\u001b[38;5;241m=\u001b[39mparam)\n\u001b[1;32m      7\u001b[0m netmhc_sub_wide \u001b[38;5;241m=\u001b[39m netmhc_sub_wide\u001b[38;5;241m.\u001b[39mreset_index() \u001b[38;5;66;03m# this is to make sure that you have the gene_var column in there too \u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'netmhc' is not defined"
     ]
    }
   ],
   "source": [
    "# 1 get binding affinities \n",
    "\n",
    "# create a suitably formatted NetMHC df \n",
    "param = 'Aff_nM'\n",
    "netmhc_sub = netmhc[['HLA_formatted', 'gene_var_gt', param]]\n",
    "netmhc_sub_wide = pd.pivot(netmhc_sub, index='gene_var_gt', columns='HLA_formatted', values=param)\n",
    "netmhc_sub_wide = netmhc_sub_wide.reset_index() # this is to make sure that you have the gene_var column in there too \n",
    "netmhc_sub_wide.columns = map(transform_format_netmhc, netmhc_sub_wide.columns)\n",
    "\n",
    "# create a list of HLA alleles genotyped in the UKBB for which predictions are available\n",
    "hla_intersect = netmhc_sub_wide.columns[netmhc_sub_wide.columns.isin(hla_ukbb)] # HLA in the UKBB which I have predictions for \n",
    "hla_intersect_list = hla_intersect.tolist() # 194 alleles \n",
    "\n",
    "# create the prediction dataset \n",
    "netmhc_sub = netmhc_sub_wide[hla_intersect_list + netmhc_sub_wide.columns[netmhc_sub_wide.columns.str.contains('gene_var')].tolist()] # subset netmhc so you only have alleles which are in the UKBB, also 194\n",
    "netmhc_sub = netmhc_sub[netmhc_sub['gene_var_gt'].str.contains('_ch', regex=True)] # retain CH scores only \n",
    "netmhc_sub['gene_var'] = netmhc_sub['gene_var_gt'].str.replace('_ch', '') # remove the ch / refseq annotation\n",
    "netmhc_sub['gene_var'] = netmhc_sub['gene_var'].str.replace('_refseq', '') # remove refseq if present \n",
    "\n",
    "# apply the function to find, for each participant, the best score for each examined CH variant \n",
    "# you take your current df and apply, row by row, the function to get scores for each variant \n",
    "# for the purpose of this, we first need to select MHC columns which are actually in the hla_intersect_list I think \n",
    "# DO NOT use this for sth like MHC heterozygosity tho!!\n",
    "df_hla1_hlas = pd.concat([df_hla1[['Person_ID', 'gene_var', 'VAF', 'ch_status', 'age']], df_hla1[hla_intersect_list]], axis = 1)\n",
    "df_hla1_scores = pd.concat([df_hla1_hlas, df_hla1_hlas.apply(find_best_score_for_all_variants, df=netmhc_sub, param=param, axis=1)], axis=1)\n",
    "\n",
    "# print the df (just check it looks okay)\n",
    "# add extra columns (read depth etc + MHC data)\n",
    "df_hla1_scores_added = pd.concat([df_hla1_scores, df_hla1[['het_allele_I_A', 'het_allele_I_B', 'het_allele_I_C', 'sum_class_I', 'het_all_class_I', 'het_all_class_I_from_allele', 'depth', 'var_depth']]], axis = 1)\n",
    "\n",
    "# save to a file (this is already usable for further analysis)\n",
    "df_hla1_scores_added.to_csv('/Users/barbarawalkowiak/Desktop/msc_thesis/results/20240820_netmhc1_scores_for_all_var_bindaff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels \n",
    "\n",
    "# add median scores\n",
    "\n",
    "# subset the dataframe to only include gene_var, Person ID and scores \n",
    "scores_col = [col for col in df_hla1_scores_added.columns if col.startswith('score_')]\n",
    "df_hla1_scores_sub = pd.concat([df_hla1_scores_added[['Person_ID', 'gene_var']], df_hla1_scores_added[scores_col]], axis = 1)\n",
    "\n",
    "# melt the dataframe \n",
    "df_hla1_scores_sub_melted = pd.melt(df_hla1_scores_sub, id_vars = ['gene_var', 'Person_ID'])\n",
    "\n",
    "# add a column which has the name of the variant (nicely formatted)\n",
    "df_hla1_scores_sub_melted['CH_variant'] = df_hla1_scores_sub_melted['variable'].str[6:]\n",
    "\n",
    "# add a column to indicate CH status (either carrier of the variant the score is for, or non-carrier, even if have CH driven by sth else)\n",
    "df_hla1_scores_sub_melted['CH_status'] = np.where(df_hla1_scores_sub_melted['gene_var'] == df_hla1_scores_sub_melted['CH_variant'].replace(), 'carrier', 'non-carrier')\n",
    "\n",
    "# you want the %Rank_EL to be in the format of -1*log10(%Rank_EL)\n",
    "df_hla1_scores_sub_melted['log_score'] = -1 * np.log10(df_hla1_scores_sub_melted['value'])\n",
    "\n",
    "# add median score for each variant and then order them by median \n",
    "df_hla1_scores_sub_melted['median_score'] = df_hla1_scores_sub_melted.groupby('CH_variant')['log_score'].transform('median')\n",
    "\n",
    "# convert to categories \n",
    "df_hla1_scores_sub_melted['gene_var'] = df_hla1_scores_sub_melted['gene_var'].astype('category') \n",
    "df_hla1_scores_sub_melted['CH_variant'] = df_hla1_scores_sub_melted['CH_variant'].astype('category')\n",
    "\n",
    "variants = df_hla1_scores_sub_melted.CH_variant.unique().tolist()\n",
    "\n",
    "for var in variants:\n",
    "\n",
    "    # select df with variant \n",
    "    df_variant = df_hla1_scores_sub_melted[df_hla1_scores_sub_melted['CH_variant'] == var]\n",
    "    \n",
    "    # get the median \n",
    "    median_score = df_variant['log_score'].median()\n",
    "    \n",
    "    # find median values \n",
    "    median_values = df_variant[df_variant['log_score'] == df_variant['median_score']]\n",
    "    \n",
    "    # assign top / bottom if above or below median \n",
    "    below_median = df_variant[df_variant['log_score'] < median_score]\n",
    "    above_median = df_variant[df_variant['log_score'] > median_score]\n",
    "    \n",
    "    # figure out how many observations you need with median values to top / bottom half\n",
    "    half_length = len(df_variant) // 2\n",
    "    num_bottom_needed = half_length - len(below_median)\n",
    "    num_top_needed = len(median_values) - num_bottom_needed\n",
    "    \n",
    "    # assign values equal to median to top or bottom\n",
    "    shuffled_median_values = median_values.sample(frac=1)\n",
    "    bottom_half_median = shuffled_median_values.iloc[:num_bottom_needed]\n",
    "    top_half_median = shuffled_median_values.iloc[num_bottom_needed:]\n",
    "    \n",
    "    # assign groups\n",
    "    df_hla1_scores_sub_melted.loc[below_median.index, 'group'] = 'bottom half'\n",
    "    df_hla1_scores_sub_melted.loc[above_median.index, 'group'] = 'top half'\n",
    "    df_hla1_scores_sub_melted.loc[bottom_half_median.index, 'group'] = 'bottom half'\n",
    "    df_hla1_scores_sub_melted.loc[top_half_median.index, 'group'] = 'top half'\n",
    "\n",
    "df_hla1_scores_sub_melted.to_csv('/Users/barbarawalkowiak/Desktop/msc_thesis/results/20240820_netmhc1_scores_for_all_var_with_labels_bindaff.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get DAI (based on %EL Rank)\n",
    "\n",
    "# DAIBA=WTBA-mutBA and DAIR=mutR/WTR\n",
    "\n",
    "netmhc['dai_rank_el'] = netmhc['%Rank_EL'] / netmhc['%Rank_EL'].shift(-1) # mutant over wt\n",
    "netmhc['dai_rank_aff'] = netmhc['Aff_nM'].shift(-1) - netmhc['Aff_nM']\n",
    "netmhc2 = netmhc.iloc[0::2].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to do something to assign, for everyone, the score for every variant we have predictions for based on their MHC I\n",
    "\n",
    "# define the function to find best scores (we can technically do this for different parameters, realistically I think will just do it for %Rank_EL)\n",
    "\n",
    "def find_best_score_for_all_variants(row, df, param):\n",
    "\n",
    "    '''\n",
    "    row = function is applied to each row of the participant dataframe (ie run through each participant)\n",
    "\n",
    "    df = dataframe with prediction scores (like netmhc)\n",
    "\n",
    "    Allowed parameters (param) are:\n",
    "    Aff_nM - affinity (raw number)\n",
    "    Score_BA - binding affinity score\n",
    "    Score_EL - elution score\n",
    "    %Rank_BA - %Rank of binding affinity cf a set of random peptides\n",
    "    %Rank_EL - %Rank of elution cf a set of random peptides\n",
    "    '''\n",
    "\n",
    "\n",
    "    # get HLAs for each person \n",
    "    hlas = row.index[5:][row[5:] >= 1] # select alleles which each Person (row) carries (the first 5 columns are: Person ID, gene_var, VAF, CH status, age)\n",
    "   \n",
    "    # get variants \n",
    "    variants = df['gene_var']\n",
    "   \n",
    "    scores = {} # initialise empy dictionaries\n",
    "\n",
    "    # depending on the parameter, pick the minimum of maximum value \n",
    "    if param == \"Aff_nM\":\n",
    "        for var in variants:\n",
    "            # Find the minimum value for each variant in the category that is present\n",
    "            best_value = min(df.loc[df['gene_var'] == var, hlas].values[0])\n",
    "            # Update the dictionary with the minimum value for the corresponding variant\n",
    "            scores[f'score_{var}'] = best_value\n",
    "        return pd.Series(scores)\n",
    "\n",
    "    elif param == \"Score_BA\":\n",
    "        for var in variants:\n",
    "            \n",
    "            best_value = max(df.loc[df['gene_var'] == var, hlas].values[0])\n",
    "            scores[f'score_{var}'] = best_value\n",
    "        \n",
    "        return pd.Series(scores)\n",
    "\n",
    "    elif param == \"Score_EL\":\n",
    "        for var in variants:\n",
    "           \n",
    "            best_value = max(df.loc[df['gene_var'] == var, hlas].values[0])\n",
    "            scores[f'score_{var}'] = best_value\n",
    "\n",
    "        return pd.Series(scores)\n",
    "\n",
    "    elif param == \"%Rank_BA\":\n",
    "        for var in variants:\n",
    "\n",
    "            best_value = min(df.loc[df['gene_var'] == var, hlas].values[0])\n",
    "            scores[f'score_{var}'] = best_value\n",
    "\n",
    "        return pd.Series(scores)\n",
    "\n",
    "    # we will likely be choosing this option\n",
    "    elif param == \"%Rank_EL\":\n",
    "        for var in variants:\n",
    "            \n",
    "            best_value = min(df.loc[df['gene_var'] == var, hlas].values[0]) # choose minimum rank as the best score \n",
    "            scores[f'score_{var}'] = best_value\n",
    "\n",
    "        return pd.Series(scores)\n",
    "\n",
    "    elif param == \"dai_rank_el\": # mutant over wt but we have small numbers so higher is better \n",
    "        for var in variants:\n",
    "            \n",
    "            best_value = min(df.loc[df['gene_var'] == var, hlas].values[0])\n",
    "            scores[f'score_{var}'] = best_value\n",
    "        \n",
    "        return pd.Series(scores)\n",
    "\n",
    "    elif param == \"dai_rank_aff\": # wt - mutant so higher is better \n",
    "        for var in variants:\n",
    "            \n",
    "            best_value = max(df.loc[df['gene_var'] == var, hlas].values[0])\n",
    "            scores[f'score_{var}'] = best_value\n",
    "        \n",
    "        return pd.Series(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param = 'dai_rank_el'\n",
    "netmhc_sub = netmhc2[['HLA_formatted', 'gene_var_gt', param]]\n",
    "netmhc_sub_wide = pd.pivot(netmhc_sub, index='gene_var_gt', columns='HLA_formatted', values=param)\n",
    "netmhc_sub_wide = netmhc_sub_wide.reset_index() # this is to make sure that you have the gene_var column in there too \n",
    "netmhc_sub_wide.columns = map(transform_format_netmhc, netmhc_sub_wide.columns)\n",
    "\n",
    "# create a list of HLA alleles genotyped in the UKBB for which predictions are available\n",
    "hla_intersect = netmhc_sub_wide.columns[netmhc_sub_wide.columns.isin(hla_ukbb)] # HLA in the UKBB which I have predictions for \n",
    "hla_intersect_list = hla_intersect.tolist() # 194 alleles \n",
    "\n",
    "# create the prediction dataset \n",
    "netmhc_sub = netmhc_sub_wide[hla_intersect_list + netmhc_sub_wide.columns[netmhc_sub_wide.columns.str.contains('gene_var')].tolist()] # subset netmhc so you only have alleles which are in the UKBB, also 194\n",
    "netmhc_sub = netmhc_sub[netmhc_sub['gene_var_gt'].str.contains('_ch', regex=True)] # retain CH scores only \n",
    "netmhc_sub['gene_var'] = netmhc_sub['gene_var_gt'].str.replace('_ch', '') # remove the ch / refseq annotation\n",
    "netmhc_sub['gene_var'] = netmhc_sub['gene_var'].str.replace('_refseq', '') # remove refseq if present \n",
    "\n",
    "# apply the function to find, for each participant, the best score for each examined CH variant \n",
    "# you take your current df and apply, row by row, the function to get scores for each variant \n",
    "# for the purpose of this, we first need to select MHC columns which are actually in the hla_intersect_list I think \n",
    "# DO NOT use this for sth like MHC heterozygosity tho!!\n",
    "df_hla1_hlas = pd.concat([df_hla1[['Person_ID', 'gene_var', 'VAF', 'ch_status', 'age']], df_hla1[hla_intersect_list]], axis = 1)\n",
    "df_hla1_scores = pd.concat([df_hla1_hlas, df_hla1_hlas.apply(find_best_score_for_all_variants, df=netmhc_sub, param=param, axis=1)], axis=1)\n",
    "\n",
    "# print the df (just check it looks okay)\n",
    "# add extra columns (read depth etc + MHC data)\n",
    "df_hla1_scores_added = pd.concat([df_hla1_scores, df_hla1[['het_allele_I_A', 'het_allele_I_B', 'het_allele_I_C', 'sum_class_I', 'het_all_class_I', 'het_all_class_I_from_allele', 'depth', 'var_depth']]], axis = 1)\n",
    "\n",
    "# save to a file (this is already usable for further analysis)\n",
    "df_hla1_scores_added.to_csv('/Users/barbarawalkowiak/Desktop/msc_thesis/results/20240820_netmhc1_scores_for_all_var_dai_rank_el.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels \n",
    "\n",
    "# add median scores\n",
    "\n",
    "# subset the dataframe to only include gene_var, Person ID and scores \n",
    "scores_col = [col for col in df_hla1_scores_added.columns if col.startswith('score_')]\n",
    "df_hla1_scores_sub = pd.concat([df_hla1_scores_added[['Person_ID', 'gene_var']], df_hla1_scores_added[scores_col]], axis = 1)\n",
    "\n",
    "# melt the dataframe \n",
    "df_hla1_scores_sub_melted = pd.melt(df_hla1_scores_sub, id_vars = ['gene_var', 'Person_ID'])\n",
    "\n",
    "# add a column which has the name of the variant (nicely formatted)\n",
    "df_hla1_scores_sub_melted['CH_variant'] = df_hla1_scores_sub_melted['variable'].str[6:]\n",
    "\n",
    "# add a column to indicate CH status (either carrier of the variant the score is for, or non-carrier, even if have CH driven by sth else)\n",
    "df_hla1_scores_sub_melted['CH_status'] = np.where(df_hla1_scores_sub_melted['gene_var'] == df_hla1_scores_sub_melted['CH_variant'].replace(), 'carrier', 'non-carrier')\n",
    "\n",
    "# you want the %Rank_EL to be in the format of -1*log10(%Rank_EL)\n",
    "df_hla1_scores_sub_melted['log_score'] = -1 * np.log10(df_hla1_scores_sub_melted['value'])\n",
    "\n",
    "# add median score for each variant and then order them by median \n",
    "df_hla1_scores_sub_melted['median_score'] = df_hla1_scores_sub_melted.groupby('CH_variant')['log_score'].transform('median')\n",
    "\n",
    "# convert to categories \n",
    "df_hla1_scores_sub_melted['gene_var'] = df_hla1_scores_sub_melted['gene_var'].astype('category') \n",
    "df_hla1_scores_sub_melted['CH_variant'] = df_hla1_scores_sub_melted['CH_variant'].astype('category')\n",
    "\n",
    "variants = df_hla1_scores_sub_melted.CH_variant.unique().tolist()\n",
    "\n",
    "for var in variants:\n",
    "\n",
    "    # select df with variant \n",
    "    df_variant = df_hla1_scores_sub_melted[df_hla1_scores_sub_melted['CH_variant'] == var]\n",
    "    \n",
    "    # get the median \n",
    "    median_score = df_variant['log_score'].median()\n",
    "    \n",
    "    # find median values \n",
    "    median_values = df_variant[df_variant['log_score'] == df_variant['median_score']]\n",
    "    \n",
    "    # assign top / bottom if above or below median \n",
    "    below_median = df_variant[df_variant['log_score'] < median_score]\n",
    "    above_median = df_variant[df_variant['log_score'] > median_score]\n",
    "    \n",
    "    # figure out how many observations you need with median values to top / bottom half\n",
    "    half_length = len(df_variant) // 2\n",
    "    num_bottom_needed = half_length - len(below_median)\n",
    "    num_top_needed = len(median_values) - num_bottom_needed\n",
    "    \n",
    "    # assign values equal to median to top or bottom\n",
    "    shuffled_median_values = median_values.sample(frac=1)\n",
    "    bottom_half_median = shuffled_median_values.iloc[:num_bottom_needed]\n",
    "    top_half_median = shuffled_median_values.iloc[num_bottom_needed:]\n",
    "    \n",
    "    # assign groups\n",
    "    df_hla1_scores_sub_melted.loc[below_median.index, 'group'] = 'bottom half'\n",
    "    df_hla1_scores_sub_melted.loc[above_median.index, 'group'] = 'top half'\n",
    "    df_hla1_scores_sub_melted.loc[bottom_half_median.index, 'group'] = 'bottom half'\n",
    "    df_hla1_scores_sub_melted.loc[top_half_median.index, 'group'] = 'top half'\n",
    "\n",
    "df_hla1_scores_sub_melted.to_csv('/Users/barbarawalkowiak/Desktop/msc_thesis/results/20240820_netmhc1_scores_for_all_var_with_labels_dai_rank_el.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 'dai_rank_aff'\n",
    "netmhc_sub = netmhc2[['HLA_formatted', 'gene_var_gt', param]]\n",
    "netmhc_sub_wide = pd.pivot(netmhc_sub, index='gene_var_gt', columns='HLA_formatted', values=param)\n",
    "netmhc_sub_wide = netmhc_sub_wide.reset_index() # this is to make sure that you have the gene_var column in there too \n",
    "netmhc_sub_wide.columns = map(transform_format_netmhc, netmhc_sub_wide.columns)\n",
    "\n",
    "# create a list of HLA alleles genotyped in the UKBB for which predictions are available\n",
    "hla_intersect = netmhc_sub_wide.columns[netmhc_sub_wide.columns.isin(hla_ukbb)] # HLA in the UKBB which I have predictions for \n",
    "hla_intersect_list = hla_intersect.tolist() # 194 alleles \n",
    "\n",
    "# create the prediction dataset \n",
    "netmhc_sub = netmhc_sub_wide[hla_intersect_list + netmhc_sub_wide.columns[netmhc_sub_wide.columns.str.contains('gene_var')].tolist()] # subset netmhc so you only have alleles which are in the UKBB, also 194\n",
    "netmhc_sub = netmhc_sub[netmhc_sub['gene_var_gt'].str.contains('_ch', regex=True)] # retain CH scores only \n",
    "netmhc_sub['gene_var'] = netmhc_sub['gene_var_gt'].str.replace('_ch', '') # remove the ch / refseq annotation\n",
    "netmhc_sub['gene_var'] = netmhc_sub['gene_var'].str.replace('_refseq', '') # remove refseq if present \n",
    "\n",
    "# apply the function to find, for each participant, the best score for each examined CH variant \n",
    "# you take your current df and apply, row by row, the function to get scores for each variant \n",
    "# for the purpose of this, we first need to select MHC columns which are actually in the hla_intersect_list I think \n",
    "# DO NOT use this for sth like MHC heterozygosity tho!!\n",
    "df_hla1_hlas = pd.concat([df_hla1[['Person_ID', 'gene_var', 'VAF', 'ch_status', 'age']], df_hla1[hla_intersect_list]], axis = 1)\n",
    "df_hla1_scores = pd.concat([df_hla1_hlas, df_hla1_hlas.apply(find_best_score_for_all_variants, df=netmhc_sub, param=param, axis=1)], axis=1)\n",
    "\n",
    "# print the df (just check it looks okay)\n",
    "# add extra columns (read depth etc + MHC data)\n",
    "df_hla1_scores_added = pd.concat([df_hla1_scores, df_hla1[['het_allele_I_A', 'het_allele_I_B', 'het_allele_I_C', 'sum_class_I', 'het_all_class_I', 'het_all_class_I_from_allele', 'depth', 'var_depth']]], axis = 1)\n",
    "\n",
    "# save to a file (this is already usable for further analysis)\n",
    "df_hla1_scores_added.to_csv('/Users/barbarawalkowiak/Desktop/msc_thesis/results/20240820_netmhc1_scores_for_all_var_dai_aff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# add labels \n",
    "# add labels \n",
    "\n",
    "# add median scores\n",
    "\n",
    "# subset the dataframe to only include gene_var, Person ID and scores \n",
    "scores_col = [col for col in df_hla1_scores_added.columns if col.startswith('score_')]\n",
    "df_hla1_scores_sub = pd.concat([df_hla1_scores_added[['Person_ID', 'gene_var']], df_hla1_scores_added[scores_col]], axis = 1)\n",
    "\n",
    "# melt the dataframe \n",
    "df_hla1_scores_sub_melted = pd.melt(df_hla1_scores_sub, id_vars = ['gene_var', 'Person_ID'])\n",
    "\n",
    "# add a column which has the name of the variant (nicely formatted)\n",
    "df_hla1_scores_sub_melted['CH_variant'] = df_hla1_scores_sub_melted['variable'].str[6:]\n",
    "\n",
    "# add a column to indicate CH status (either carrier of the variant the score is for, or non-carrier, even if have CH driven by sth else)\n",
    "df_hla1_scores_sub_melted['CH_status'] = np.where(df_hla1_scores_sub_melted['gene_var'] == df_hla1_scores_sub_melted['CH_variant'].replace(), 'carrier', 'non-carrier')\n",
    "\n",
    "# NOTE: not doing log score here (because I want to know if the difference is positive / negative)\n",
    "# add median score for each variant and then order them by median \n",
    "df_hla1_scores_sub_melted['median_score'] = df_hla1_scores_sub_melted.groupby('CH_variant')['value'].transform('median')\n",
    "\n",
    "# convert to categories \n",
    "df_hla1_scores_sub_melted['gene_var'] = df_hla1_scores_sub_melted['gene_var'].astype('category') \n",
    "df_hla1_scores_sub_melted['CH_variant'] = df_hla1_scores_sub_melted['CH_variant'].astype('category')\n",
    "\n",
    "variants = df_hla1_scores_sub_melted.CH_variant.unique().tolist()\n",
    "\n",
    "for var in variants:\n",
    "\n",
    "    # select df with variant \n",
    "    df_variant = df_hla1_scores_sub_melted[df_hla1_scores_sub_melted['CH_variant'] == var]\n",
    "    \n",
    "    # get the median \n",
    "    median_score = df_variant['value'].median()\n",
    "    \n",
    "    # find median values \n",
    "    median_values = df_variant[df_variant['value'] == df_variant['median_score']]\n",
    "    \n",
    "    # assign top / bottom if above or below median \n",
    "    below_median = df_variant[df_variant['value'] < median_score]\n",
    "    above_median = df_variant[df_variant['value'] > median_score]\n",
    "    \n",
    "    # figure out how many observations you need with median values to top / bottom half\n",
    "    half_length = len(df_variant) // 2\n",
    "    num_bottom_needed = half_length - len(below_median)\n",
    "    num_top_needed = len(median_values) - num_bottom_needed\n",
    "    \n",
    "    # assign values equal to median to top or bottom\n",
    "    shuffled_median_values = median_values.sample(frac=1)\n",
    "    bottom_half_median = shuffled_median_values.iloc[:num_bottom_needed]\n",
    "    top_half_median = shuffled_median_values.iloc[num_bottom_needed:]\n",
    "    \n",
    "    # assign groups\n",
    "    df_hla1_scores_sub_melted.loc[below_median.index, 'group'] = 'bottom half'\n",
    "    df_hla1_scores_sub_melted.loc[above_median.index, 'group'] = 'top half'\n",
    "    df_hla1_scores_sub_melted.loc[bottom_half_median.index, 'group'] = 'bottom half'\n",
    "    df_hla1_scores_sub_melted.loc[top_half_median.index, 'group'] = 'top half'\n",
    "\n",
    "df_hla1_scores_sub_melted.to_csv('/Users/barbarawalkowiak/Desktop/msc_thesis/results/20240820_netmhc1_scores_for_all_var_with_labels_dai_rank_aff.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
